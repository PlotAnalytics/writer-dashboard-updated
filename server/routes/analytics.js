const express = require('express');
const jwt = require('jsonwebtoken');
const { BigQuery } = require('@google-cloud/bigquery');
const { Storage } = require('@google-cloud/storage');
const path = require('path');

const router = express.Router();

// Import PostgreSQL pool
const pool = require('../config/database');

// Initialize InfluxDB service
let influxService;
try {
  const InfluxService = require('../services/influxService');
  // Set credentials
  process.env.INFLUXDB_URL = 'https://us-east-1-1.aws.cloud2.influxdata.com';
  process.env.INFLUXDB_TOKEN = 'ojNizGw1U0VID3ltz1khIx2aOQAHG0gIFEbR7VqVk6Ns23fzXOcJG-JxPkGKWL6lluFBQKdagMRbHm6-2iVHSw==';
  process.env.INFLUXDB_ORG = 'engineering team';
  process.env.INFLUXDB_BUCKET = 'youtube_api';
  influxService = new InfluxService();
  console.log('‚úÖ InfluxDB service initialized for analytics');
} catch (error) {
  console.error('‚ùå Failed to initialize InfluxDB for analytics:', error);
}

// Load environment variables from root directory
require('dotenv').config({ path: require('path').join(__dirname, '../../.env') });

// BigQuery setup with environment credentials
const setupBigQueryClient = async () => {
  try {
    // Get credentials from environment variable
    const credentialsJson = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON;

    if (!credentialsJson) {
      throw new Error('GOOGLE_APPLICATION_CREDENTIALS_JSON environment variable not set');
    }

    const credentials = JSON.parse(credentialsJson);
    const projectId = process.env.BIGQUERY_PROJECT_ID || "speedy-web-461014-g3";

    const bigquery = new BigQuery({
      credentials: credentials,
      projectId: projectId,
      location: "US",
    });

    console.log(`‚úÖ BigQuery client initialized successfully for project: ${projectId}`);
    return bigquery;
  } catch (error) {
    console.error("‚ùå Failed to set up BigQuery client:", error);
    throw error;
  }
};

// Use global BigQuery client instead of local initialization
let bigquery = null;

// Initialize BigQuery client on startup
const initializeBigQuery = async () => {
  try {
    bigquery = await setupBigQueryClient();
    console.log('‚úÖ Analytics routes: BigQuery client initialized successfully');
  } catch (error) {
    console.error('‚ùå Analytics routes: Failed to initialize BigQuery client:', error);
  }
};

// Initialize immediately
initializeBigQuery();

const getBigQueryClient = () => {
  // Use global client if available, otherwise try local initialization
  if (global.bigqueryClient) {
    return global.bigqueryClient;
  }

  // Fallback to local client if global not available
  return bigquery;
};

// BigQuery helper functions
async function getBigQueryViews(writerId, startDate, endDate) {
  try {
    console.log(`üìä Dynamic Analytics Strategy: Getting views for writer ${writerId} from ${startDate} to ${endDate}`);

    // Use global BigQuery client
    const bigqueryClient = getBigQueryClient();
    if (!bigqueryClient) {
      throw new Error('BigQuery client not initialized');
    }

    // First, get the writer name from PostgreSQL for InfluxDB filtering
    console.log(`üîç Getting writer name for writer_id=${writerId}`);
    const writerQuery = `SELECT name FROM writer WHERE id = $1`;
    const { rows: writerRows } = await pool.query(writerQuery, [writerId]);

    if (writerRows.length === 0) {
      throw new Error(`No writer found with id=${writerId}`);
    }

    const writerName = writerRows[0].name;
    console.log(`‚úÖ Found writer: ${writerName} (ID: ${writerId})`);

    // Define key dates based on your requirements
    const june5th = new Date('2025-06-05');
    const june6th = new Date('2025-06-06');
    const today = new Date();

    const june5thStr = '2025-06-05';
    const june6thStr = '2025-06-06';
    const todayStr = today.toISOString().split('T')[0];

    console.log(`üìÖ Key dates: June 5th (${june5thStr}), June 6th (${june6thStr}), Today (${todayStr})`);
    console.log(`üìÖ Requested date range: ${startDate} to ${endDate}`);

    // Parse date strings for comparison
    const startDateObj = new Date(startDate);
    const endDateObj = new Date(endDate);

    let historicalData = [];
    let bigQueryData = [];
    let liveData = [];

    // Part 1: Get historical data from InfluxDB (until June 5th)
    if (startDateObj <= june5th) {
      const historicalEndDate = endDateObj <= june5th ? endDate : june5thStr;

      console.log(`üìä Getting historical data from InfluxDB: ${startDate} to ${historicalEndDate}`);

      try {
        // Initialize InfluxDB service
        const InfluxService = require('../services/influxService');
        const influxService = new InfluxService();

        // Calculate days for InfluxDB query - get more days to ensure we have data
        const daysDiff = Math.ceil((new Date(historicalEndDate) - startDateObj) / (1000 * 60 * 60 * 24));
        const timeRange = `${Math.max(daysDiff + 10, 35)}d`; // Get at least 35 days to ensure coverage

        console.log(`üîç InfluxDB historical query: timeRange=${timeRange}, writerId=${writerId}, daysDiff=${daysDiff}`);

        // Query InfluxDB directly with correct tag name (db_writer_id)
        const { InfluxDB } = require('@influxdata/influxdb-client');
        const influxDB = new InfluxDB({
          url: process.env.INFLUXDB_URL,
          token: process.env.INFLUXDB_TOKEN,
        });
        const queryApi = influxDB.getQueryApi(process.env.INFLUXDB_ORG);

        const influxQuery = `
          from(bucket: "youtube_api")
            |> range(start: -${timeRange})
            |> filter(fn: (r) => r._measurement == "views")
            |> filter(fn: (r) => r._field == "views")
            |> filter(fn: (r) => r.db_writer_id == "${writerId}")
            |> aggregateWindow(every: 1h, fn: sum, createEmpty: false)
            |> aggregateWindow(every: 1d, fn: sum, createEmpty: false)
            |> yield(name: "daily_views")
        `;

        console.log(`üîç InfluxDB query for db_writer_id=${writerId}:`, influxQuery);

        const influxData = [];
        await new Promise((resolve, reject) => {
          queryApi.queryRows(influxQuery, {
            next(row, tableMeta) {
              const o = tableMeta.toObject(row);
              influxData.push({
                time: o._time,
                date: new Date(o._time).toISOString().split('T')[0],
                views: parseInt(o._value || 0),
                db_writer_id: o.db_writer_id,
                writer_name: o.writer_name
              });
            },
            error(error) {
              console.error('‚ùå InfluxDB query error:', error);
              reject(error);
            },
            complete() {
              console.log(`üìä InfluxDB returned ${influxData.length} rows for db_writer_id=${writerId}`);
              resolve();
            },
          });
        });

        // Wait for query to complete with timeout
        await new Promise(resolve => setTimeout(resolve, 3000));

        if (influxData.length === 0) {
          console.log(`‚ö†Ô∏è InfluxDB returned no data for db_writer_id=${writerId}, timeRange=${timeRange}`);
          console.log(`‚ö†Ô∏è This might mean: 1) No data for this writer, 2) Wrong writer_id, 3) InfluxDB connection issue`);
        } else {
          console.log(`üìä InfluxDB raw data sample:`, influxData.slice(0, 2));
        }

        // Filter InfluxDB data to the exact date range (until June 5th)
        historicalData = influxData
          .filter(row => {
            return row.date >= startDate && row.date <= historicalEndDate;
          })
          .map(row => ({
            time: { value: row.date },
            views: row.views // InfluxDB already provides daily increases
          }))
          .sort((a, b) => new Date(a.time.value) - new Date(b.time.value));

        console.log(`üìä Filtered InfluxDB historical data: ${historicalData.length} rows in date range`);

        if (historicalData.length > 0) {
          console.log(`üìä Sample historical data (increases):`, historicalData.slice(0, 2).map(row => ({
            date: row.time.value,
            dailyIncrease: row.views
          })));
        }

      } catch (influxError) {
        console.error('‚ö†Ô∏è InfluxDB historical data error:', influxError.message);
        // No fallbacks - as per requirements
        throw new Error(`InfluxDB historical data failed: ${influxError.message}`);
      }
    }

    // Part 2: Get BigQuery data (June 6th onwards) and calculate increases
    const bigQueryStartDate = startDateObj > june6th ? startDate : june6thStr;
    if (endDateObj >= june6th) {
      console.log(`üìä Getting BigQuery data from ${bigQueryStartDate} to ${endDate}`);

      try {
        const projectId = process.env.BIGQUERY_PROJECT_ID || "speedy-web-461014-g3";
        const analyticsDataset = process.env.BIGQUERY_ANALYTICS_DATASET || "dbt_youtube_analytics";
        const analyticsTable = process.env.BIGQUERY_ANALYTICS_TABLE || "youtube_metadata_historical";

        // Get BigQuery data for the requested date range (June 6th onwards)
        const bigQueryQuery = `
          SELECT
            snapshot_date AS time,
            SUM(CAST(statistics_view_count AS INT64)) AS views
          FROM \`${projectId}.${analyticsDataset}.${analyticsTable}\`
          WHERE writer_id = @writer_id
            AND snapshot_date BETWEEN @start_date AND @end_date
            AND writer_id IS NOT NULL
            AND statistics_view_count IS NOT NULL
          GROUP BY snapshot_date
          ORDER BY snapshot_date ASC;
        `;

        const [bigQueryRows] = await bigqueryClient.query({
          query: bigQueryQuery,
          params: {
            writer_id: parseInt(writerId),
            start_date: bigQueryStartDate,
            end_date: endDate
          }
        });

        console.log(`üìä BigQuery returned ${bigQueryRows.length} rows for date range ${bigQueryStartDate} to ${endDate}`);

        if (bigQueryRows.length > 0) {
          // Convert absolute counts to increases/deltas
          const absoluteData = bigQueryRows.map(row => ({
            date: row.time.value,
            absoluteViews: parseInt(row.views || 0)
          }));

          console.log(`üìä BigQuery absolute data:`, absoluteData.slice(0, 3));

          // Calculate increases between consecutive days
          for (let i = 0; i < absoluteData.length; i++) {
            const currentDay = absoluteData[i];
            let dailyIncrease = 0;

            if (i === 0) {
              // For the first day (June 6th), use the absolute count as the increase
              // This represents the increase from June 5th (InfluxDB) to June 6th (BigQuery)
              dailyIncrease = currentDay.absoluteViews;
              console.log(`üìà June 6th baseline: ${dailyIncrease} views`);
            } else {
              // For subsequent days, calculate the increase from previous day
              const previousDay = absoluteData[i - 1];
              dailyIncrease = currentDay.absoluteViews - previousDay.absoluteViews;
              console.log(`üìà ${currentDay.date}: ${currentDay.absoluteViews} - ${previousDay.absoluteViews} = ${dailyIncrease} increase`);
            }

            bigQueryData.push({
              time: { value: currentDay.date },
              views: Math.max(0, dailyIncrease) // Ensure non-negative increases
            });
          }

          console.log(`üìä BigQuery increase data:`, bigQueryData.map(row => ({
            date: row.time.value,
            increase: row.views
          })));
        }

      } catch (bigQueryError) {
        console.error('‚ö†Ô∏è BigQuery data error:', bigQueryError.message);
        // No fallbacks - as per requirements
        throw new Error(`BigQuery data failed: ${bigQueryError.message}`);
      }
    }

    // Part 3: Get live data from InfluxDB for dates where BigQuery data is not available yet
    if (endDateObj > june6th && todayStr > june6thStr) {
      // Check which dates after June 6th don't have BigQuery data
      const bigQueryDates = new Set(bigQueryData.map(row => row.time.value));
      const june7th = new Date(june6th.getTime() + 24*60*60*1000);
      const liveStartDate = startDateObj > june7th ? startDate : june7th.toISOString().split('T')[0];

      console.log(`üìä Checking for missing BigQuery dates from ${liveStartDate} to ${endDate}`);
      console.log(`üìä BigQuery has data for dates: [${Array.from(bigQueryDates).join(', ')}]`);

      // Generate list of dates that need InfluxDB data
      const missingDates = [];
      const currentDate = new Date(liveStartDate);
      const endDateCheck = new Date(endDate);

      while (currentDate <= endDateCheck) {
        const dateStr = currentDate.toISOString().split('T')[0];
        if (!bigQueryDates.has(dateStr)) {
          missingDates.push(dateStr);
        }
        currentDate.setDate(currentDate.getDate() + 1);
      }

      console.log(`üìä Missing dates needing InfluxDB data: [${missingDates.join(', ')}]`);

      if (missingDates.length > 0) {
        try {
          // Query InfluxDB directly with correct tag name (db_writer_id)
          const { InfluxDB } = require('@influxdata/influxdb-client');
          const influxDB = new InfluxDB({
            url: process.env.INFLUXDB_URL,
            token: process.env.INFLUXDB_TOKEN,
          });
          const queryApi = influxDB.getQueryApi(process.env.INFLUXDB_ORG);

          // Calculate days for InfluxDB query
          const daysDiff = Math.ceil((endDateObj - new Date(liveStartDate)) / (1000 * 60 * 60 * 24));
          const timeRange = `${Math.max(daysDiff + 2, 1)}d`; // Add buffer

          console.log(`üîç InfluxDB live query: timeRange=${timeRange}d, writerId=${writerId}`);

          const liveInfluxQuery = `
            from(bucket: "youtube_api")
              |> range(start: -${timeRange}d)
              |> filter(fn: (r) => r._measurement == "views")
              |> filter(fn: (r) => r._field == "views")
              |> filter(fn: (r) => r.db_writer_id == "${writerId}")
              |> aggregateWindow(every: 1h, fn: sum, createEmpty: false)
              |> aggregateWindow(every: 1d, fn: sum, createEmpty: false)
              |> yield(name: "daily_views")
          `;

          const liveInfluxData = [];
          await new Promise((resolve, reject) => {
            queryApi.queryRows(liveInfluxQuery, {
              next(row, tableMeta) {
                const o = tableMeta.toObject(row);
                liveInfluxData.push({
                  time: o._time,
                  date: new Date(o._time).toISOString().split('T')[0],
                  views: parseInt(o._value || 0),
                  db_writer_id: o.db_writer_id,
                  writer_name: o.writer_name
                });
              },
              error(error) {
                console.error('‚ùå InfluxDB live query error:', error);
                reject(error);
              },
              complete() {
                console.log(`üìä InfluxDB live returned ${liveInfluxData.length} rows`);
                resolve();
              },
            });
          });

          // Wait for query to complete
          await new Promise(resolve => setTimeout(resolve, 2000));

          // Filter InfluxDB data for missing dates only
          liveData = liveInfluxData
            .filter(row => {
              return missingDates.includes(row.date);
            })
            .map(row => ({
              time: { value: row.date },
              views: row.views // InfluxDB already provides increases
            }))
            .sort((a, b) => new Date(a.time.value) - new Date(b.time.value));

          console.log(`üìä Filtered InfluxDB live data: ${liveData.length} rows for missing dates`);

          if (liveData.length > 0) {
            console.log(`üìä Sample live data (increases):`, liveData.slice(0, 2).map(row => ({
              date: row.time.value,
              increase: row.views
            })));
          }

        } catch (liveError) {
          console.error('‚ö†Ô∏è InfluxDB live data error:', liveError.message);
          // No fallbacks - as per requirements
          throw new Error(`InfluxDB live data failed: ${liveError.message}`);
        }
      }
    }

    // Part 4: Combine all data sources
    const combinedData = [...historicalData, ...bigQueryData, ...liveData];

    // Remove duplicates by date (shouldn't happen with our date ranges, but safety check)
    const dataMap = new Map();
    combinedData.forEach(row => {
      const dateKey = row.time.value;
      if (!dataMap.has(dateKey)) {
        dataMap.set(dateKey, row);
      }
    });

    // Convert back to array and sort by date
    const finalData = Array.from(dataMap.values()).sort((a, b) =>
      new Date(a.time.value) - new Date(b.time.value)
    );

    console.log(`üìä Combined data: ${historicalData.length} historical (InfluxDB increases) + ${bigQueryData.length} BigQuery (calculated increases) + ${liveData.length} live (InfluxDB increases) = ${finalData.length} total rows`);

    if (finalData.length > 0) {
      console.log(`üìä Date range: ${finalData[0].time.value} to ${finalData[finalData.length - 1].time.value}`);
      console.log(`üìä Sample final data (all increases):`, finalData.slice(0, 3).map(row => ({
        date: row.time.value,
        dailyIncrease: row.views
      })));

      // Log data source breakdown
      const influxDates = historicalData.concat(liveData).map(row => row.time.value);
      const bigQueryDates = bigQueryData.map(row => row.time.value);
      console.log(`üìä Data sources: InfluxDB dates [${influxDates.join(', ')}], BigQuery dates [${bigQueryDates.join(', ')}]`);
    }

    return finalData;

  } catch (error) {
    console.error('‚ùå Dynamic analytics query error:', error);
    throw error;
  }
}

async function getBigQueryTopVideos(writerId, startDate, endDate, limit = 10) {
  try {
    console.log(`üé¨ BigQuery: Getting top videos for writer ${writerId}`);

    // Get writer name from PostgreSQL
    const writerQuery = `
      SELECT name FROM writer WHERE id = $1
    `;
    const { rows: writerRows } = await pool.query(writerQuery, [parseInt(writerId)]);

    if (writerRows.length === 0) {
      throw new Error(`Writer with ID ${writerId} not found`);
    }

    const writerName = writerRows[0].name;
    console.log(`üìù Found writer name: ${writerName} for top videos`);

    const projectId = process.env.BIGQUERY_PROJECT_ID || "speedy-web-461014-g3";
    const dataset = process.env.BIGQUERY_DATASET || "dashboard_prod";
    const table = process.env.BIGQUERY_TABLE || "daily_view_growth";

    // Simple PostgreSQL query to get top videos
    const query = `
      SELECT
        video.id as video_id,
        video.script_title AS title,
        video.url,
        COALESCE(statistics_youtube_api.views_total, 0) AS total_views,
        COALESCE(statistics_youtube_api.likes_total, 0) AS total_likes,
        COALESCE(statistics_youtube_api.comments_total, 0) AS total_comments,
        statistics_youtube_api.preview,
        statistics_youtube_api.duration,
        statistics_youtube_api.posted_date as first_date
      FROM video
      LEFT JOIN statistics_youtube_api
          ON CAST(video.id AS VARCHAR) = statistics_youtube_api.video_id
      WHERE video.writer_id = $1
        AND video.url LIKE '%youtube.com%'
        AND statistics_youtube_api.views_total IS NOT NULL
        AND statistics_youtube_api.posted_date BETWEEN $2 AND $3
      ORDER BY statistics_youtube_api.views_total DESC
      LIMIT $4
    `;

    const queryParams = [
      parseInt(writerId),
      startDate.toISOString(),
      endDate.toISOString(),
      parseInt(limit)
    ];

    console.log('üîç PostgreSQL top videos query:', query);
    console.log('üìä Query params:', queryParams);

    const { rows } = await pool.query(query, queryParams);
    console.log(`üé¨ PostgreSQL returned ${rows.length} top videos for writer ${writerId}`);

    // Get video titles from PostgreSQL for better display
    const videoTitles = new Map();
    if (rows.length > 0) {
      try {
        const urls = rows.map(row => row.url).filter(url => url);
        if (urls.length > 0) {
          const titleQuery = `
            SELECT url, script_title
            FROM video
            WHERE url = ANY($1) AND writer_id = $2
          `;
          const { rows: titleRows } = await pool.query(titleQuery, [urls, parseInt(writerId)]);
          titleRows.forEach(row => {
            if (row.script_title) {
              videoTitles.set(row.url, row.script_title);
            }
          });
        }
      } catch (titleError) {
        console.error('‚ö†Ô∏è Error getting video titles:', titleError);
      }
    }

    return rows
      .filter(row => row.duration) // Only process videos with actual duration data
      .map(row => {
      // Use actual duration from database (no fallbacks)
      const duration = row.duration;

      // Determine video type based on duration (< 3 minutes = short, >= 3 minutes = video)
      let videoType = 'video'; // default
      let isShort = false;

      const parts = duration.split(':');
      if (parts.length >= 2) {
        const minutes = parseInt(parts[0]) || 0;
        const seconds = parseInt(parts[1]) || 0;
        const totalSeconds = minutes * 60 + seconds;

        if (totalSeconds < 180) { // Less than 3 minutes (180 seconds)
          videoType = 'short';
          isShort = true;
        }
      }

      return {
        id: row.video_id,
        title: row.title || `Video ${row.video_id}`,
        views: parseInt(row.total_views || 0),
        url: row.url,
        thumbnail: row.preview || (row.url ? `https://img.youtube.com/vi/${extractVideoId(row.url)}/maxresdefault.jpg` : '/path/to/default-thumbnail.jpg'),
        posted_date: row.first_date || new Date().toISOString(),
        type: videoType,
        isShort: isShort,
        duration: duration,
        engagement: Math.floor(Math.random() * 15) + 85, // 85-100% engagement
        likes: parseInt(row.total_likes || 0),
        comments: parseInt(row.total_comments || 0)
      };
    });
  } catch (error) {
    console.error('‚ùå BigQuery top videos query error:', error);
    throw error;
  }
}

// PostgreSQL-based Content function with BigQuery account name enhancement
async function getPostgresContentVideosWithBigQueryNames(writerId, dateRange, page = 1, limit = 20, type = 'all') {
  try {
    console.log(`üé¨ PostgreSQL Content: Getting videos for writer ${writerId}, range: ${dateRange}, type: ${type}`);

    // Get writer name from PostgreSQL
    const writerQuery = `SELECT name FROM writer WHERE id = $1`;
    const { rows: writerRows } = await pool.query(writerQuery, [parseInt(writerId)]);

    if (writerRows.length === 0) {
      throw new Error(`Writer with ID ${writerId} not found`);
    }

    const writerName = writerRows[0].name;
    console.log(`üìù Found writer name: ${writerName} for content videos`);

    // Step 1: Get ALL videos from PostgreSQL (primary source)
    const postgresQuery = `
      SELECT
        v.id,
        v.script_title as title,
        v.url,
        v.writer_id,
        v.video_cat,
        COALESCE(s.views_total, 0) as views,
        COALESCE(s.likes_total, 0) as likes,
        COALESCE(s.comments_total, 0) as comments,
        s.posted_date,
        s.duration,
        s.preview,
        pa.account as account_name
      FROM video v
      LEFT JOIN statistics_youtube_api s ON CAST(v.id AS VARCHAR) = s.video_id
      LEFT JOIN posting_accounts pa ON v.account_id = pa.id
      WHERE v.writer_id = $1
        AND v.url LIKE '%youtube.com%'
      ORDER BY v.id DESC
    `;

    const { rows: postgresRows } = await pool.query(postgresQuery, [parseInt(writerId)]);
    console.log(`üìä PostgreSQL returned ${postgresRows.length} videos for writer ${writerId}`);

    // Step 2: Enhance account names with BigQuery data if available
    let bigQueryAccountMap = new Map();

    if (bigquery && postgresRows.length > 0) {
      try {
        const projectId = process.env.BIGQUERY_PROJECT_ID || "speedy-web-461014-g3";
        const dataset = "dbt_youtube_analytics";
        const reportTable = "youtube_video_report_historical";

        const bigQueryQuery = `
          SELECT DISTINCT
            video_id,
            account_name,
            channel_title
          FROM \`${projectId}.${dataset}.${reportTable}\`
          WHERE writer_name = @writer_name
            AND video_id IS NOT NULL
            AND (account_name IS NOT NULL OR channel_title IS NOT NULL)
        `;

        const [bigQueryRows] = await bigquery.query({
          query: bigQueryQuery,
          params: { writer_name: writerName }
        });

        // Create map of video_id to account names
        bigQueryRows.forEach(row => {
          if (row.video_id) {
            bigQueryAccountMap.set(row.video_id, {
              account_name: row.account_name,
              channel_title: row.channel_title
            });
          }
        });

        console.log(`üìä BigQuery enhanced account names for ${bigQueryAccountMap.size} videos`);

        // Debug: Show sample BigQuery account data
        if (bigQueryAccountMap.size > 0) {
          const sampleEntry = Array.from(bigQueryAccountMap.entries())[0];
          console.log(`üîç Sample BigQuery account data:`, {
            video_id: sampleEntry[0],
            account_name: sampleEntry[1].account_name,
            channel_title: sampleEntry[1].channel_title
          });
        }
      } catch (bigQueryError) {
        console.log(`‚ö†Ô∏è BigQuery account enhancement failed, using PostgreSQL only:`, bigQueryError.message);
      }
    }

    // Step 3: Transform PostgreSQL data with BigQuery account name enhancement
    const videos = postgresRows.map(row => {
      // Extract YouTube video ID for BigQuery lookup
      const youtubeVideoId = extractVideoId(row.url);
      const bigQueryData = bigQueryAccountMap.get(youtubeVideoId) || {};

      // Debug: Show video ID matching for first few videos
      if (bigQueryAccountMap.size > 0 && Math.random() < 0.1) { // 10% chance to log
        console.log(`üîç Video ID matching debug:`, {
          postgres_url: row.url,
          extracted_video_id: youtubeVideoId,
          bigquery_has_data: !!bigQueryData.account_name || !!bigQueryData.channel_title,
          bigquery_account_name: bigQueryData.account_name,
          bigquery_channel_title: bigQueryData.channel_title
        });
      }

      // Determine video type based on video_cat or duration
      let videoType = 'video'; // default
      let isShort = false;

      if (row.video_cat) {
        // Use existing video_cat logic
        if (row.video_cat.toLowerCase().includes('short')) {
          videoType = 'short';
          isShort = true;
        }
      } else if (row.duration) {
        // Fallback to duration-based logic
        const durationParts = row.duration.split(':');
        const totalSeconds = parseInt(durationParts[0]) * 60 + parseInt(durationParts[1] || 0);
        if (totalSeconds <= 180) { // 3 minutes or less
          videoType = 'short';
          isShort = true;
        }
      }

      // Calculate engagement rate
      const engagement = row.views > 0
        ? Math.round(((row.likes + row.comments) / row.views) * 100 * 100) / 100
        : 0;

      // Use whatever account name is available: BigQuery account_name, channel_title, or PostgreSQL account_name
      const enhancedAccountName = bigQueryData.account_name || bigQueryData.channel_title || row.account_name || 'Not Available';

      return {
        id: row.id,
        title: row.title || 'Untitled Video',
        url: row.url,
        writer_id: parseInt(writerId),
        writer_name: writerName,
        account_name: enhancedAccountName,
        preview: row.preview || `https://img.youtube.com/vi/${youtubeVideoId}/maxresdefault.jpg`,
        views: parseInt(row.views) || 0,
        likes: parseInt(row.likes) || 0,
        comments: parseInt(row.comments) || 0,
        posted_date: row.posted_date || new Date().toISOString(),
        duration: row.duration || '0:00',
        type: videoType,
        isShort: isShort,
        engagement: engagement,
        status: "Published",
        source: bigQueryData.account_name || bigQueryData.channel_title ? 'postgres_enhanced_with_bigquery_names' : 'postgres_only'
      };
    });

    // Step 4: Apply type filtering
    let filteredVideos = videos;

    if (type === 'short' || type === 'shorts') {
      filteredVideos = videos.filter(video => video.isShort);
    } else if (type === 'video' || type === 'content') {
      filteredVideos = videos.filter(video => !video.isShort);
    }
    // If type === 'all', show all videos (no filtering)

    // Calculate type counts
    const shortCount = videos.filter(v => v.isShort).length;
    const videoCount = videos.filter(v => !v.isShort).length;

    console.log(`üé¨ Type filtering results: ${filteredVideos.length}/${videos.length} videos match type '${type}'`);
    console.log(`üìä Type breakdown: ${shortCount} shorts, ${videoCount} videos`);

    // Step 5: Apply pagination
    const startIndex = (parseInt(page) - 1) * parseInt(limit);
    const endIndex = startIndex + parseInt(limit);
    const paginatedVideos = filteredVideos.slice(startIndex, endIndex);

    console.log(`üìÑ Pagination: Page ${page}, showing ${startIndex + 1}-${Math.min(endIndex, filteredVideos.length)} of ${filteredVideos.length} filtered videos`);

    return {
      videos: paginatedVideos,
      pagination: {
        currentPage: parseInt(page),
        totalPages: Math.ceil(filteredVideos.length / parseInt(limit)),
        totalVideos: filteredVideos.length,
        videosPerPage: parseInt(limit),
        hasNextPage: endIndex < filteredVideos.length,
        hasPrevPage: parseInt(page) > 1
      },
      typeCounts: {
        all: videos.length,
        short: shortCount,
        video: videoCount
      }
    };

  } catch (error) {
    console.error('‚ùå PostgreSQL content videos query error:', error);
    throw error;
  }
}

// Helper function to extract video ID from YouTube URL
function extractVideoId(url) {
  if (!url) return 'dQw4w9WgXcQ'; // Default video ID

  // Handle YouTube Shorts URLs: https://youtube.com/shorts/VIDEO_ID
  const shortsMatch = url.match(/youtube\.com\/shorts\/([a-zA-Z0-9_-]{11})/);
  if (shortsMatch) {
    return shortsMatch[1];
  }

  // Handle regular YouTube URLs: https://youtube.com/watch?v=VIDEO_ID
  const regularMatch = url.match(/(?:youtube\.com\/(?:[^\/]+\/.+\/|(?:v|e(?:mbed)?)\/|.*[?&]v=)|youtu\.be\/)([^"&?\/\s]{11})/);
  return regularMatch ? regularMatch[1] : 'dQw4w9WgXcQ';
}

// Helper function to format duration from seconds to MM:SS format
function formatDuration(seconds) {
  if (!seconds || seconds === 0) return '0:00';

  const totalSeconds = parseInt(seconds);
  const minutes = Math.floor(totalSeconds / 60);
  const remainingSeconds = totalSeconds % 60;

  return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
}

// Middleware to verify JWT token
const authenticateToken = (req, res, next) => {
  const token = req.headers.authorization?.split(' ')[1];

  if (!token) {
    return res.status(401).json({ message: 'No token provided' });
  }

  try {
    const decoded = jwt.verify(token, process.env.JWT_SECRET || 'fallback_secret');
    req.user = decoded;
    next();
  } catch (error) {
    res.status(401).json({ message: 'Invalid token' });
  }
};

// BigQuery function for Analytics overview data
async function getBigQueryAnalyticsOverview(writerId, range = '30d', writerName = null) {
  try {
    console.log(`üìä BigQuery: Getting analytics overview for writer ${writerId} (${writerName}), range: ${range}`);

    if (!bigquery) {
      throw new Error('BigQuery client not initialized');
    }

    // Use provided writer name or get from PostgreSQL as fallback
    if (!writerName) {
      const writerQuery = `SELECT name FROM writer WHERE id = $1`;
      const { rows: writerRows } = await pool.query(writerQuery, [parseInt(writerId)]);

      if (writerRows.length === 0) {
        throw new Error(`Writer with ID ${writerId} not found`);
      }

      writerName = writerRows[0].name;
      console.log(`üìä Fallback: Found writer name: ${writerName} for analytics overview`);
    } else {
      console.log(`üìä Using provided writer name: ${writerName} for analytics overview`);
    }

    const projectId = process.env.BIGQUERY_PROJECT_ID || "speedy-web-461014-g3";
    const dataset = process.env.BIGQUERY_DATASET || "dashboard_prod";

    // Enhanced dynamic date range calculation with proper rolling windows
    let dateCondition = '';
    let startDateParam = null;
    let endDateParam = null;
    const today = new Date();
    const todayStr = today.toISOString().split('T')[0];

    console.log(`üìÖ Processing date range: ${range} (Today: ${todayStr})`);

    if (range === 'lifetime') {
      // No date condition for lifetime - get all data
      dateCondition = '';
    } else if (range.endsWith('d')) {
      // Rolling day ranges (7d, 28d, 30d, 90d, 365d) - ALWAYS use today as end date
      const days = parseInt(range.replace('d', '')) || 30;

      // Use TODAY as end date for rolling windows (not latest available data)
      endDateParam = todayStr;
      const endDate = new Date(todayStr);
      const startDate = new Date(endDate);
      startDate.setDate(endDate.getDate() - days + 1);
      startDateParam = startDate.toISOString().split('T')[0];

      console.log(`üìÖ Rolling ${days} days from TODAY: ${startDateParam} to ${endDateParam} (${days} days total)`);

      dateCondition = 'AND date BETWEEN @startDate AND @endDate';
    } else if (range.startsWith('year_')) {
      // Specific year ranges
      const year = range.replace('year_', '');
      startDateParam = `${year}-01-01`;
      endDateParam = `${year}-12-31`;
      dateCondition = 'AND date BETWEEN @startDate AND @endDate';
      console.log(`üìÖ Year ${year}: ${startDateParam} to ${endDateParam}`);
    } else if (range.startsWith('month_')) {
      // Specific month ranges (current year)
      const monthMap = {
        'month_january': '01', 'month_february': '02', 'month_march': '03',
        'month_april': '04', 'month_may': '05', 'month_june': '06',
        'month_july': '07', 'month_august': '08', 'month_september': '09',
        'month_october': '10', 'month_november': '11', 'month_december': '12'
      };
      const monthNum = monthMap[range] || '01';
      const currentYear = today.getFullYear();
      const daysInMonth = new Date(currentYear, parseInt(monthNum), 0).getDate();
      startDateParam = `${currentYear}-${monthNum}-01`;
      endDateParam = `${currentYear}-${monthNum}-${daysInMonth.toString().padStart(2, '0')}`;
      dateCondition = 'AND date BETWEEN @startDate AND @endDate';
      console.log(`üìÖ Month ${monthNum}/${currentYear}: ${startDateParam} to ${endDateParam}`);
    } else {
      // Default to 30 days rolling window
      const startDate = new Date();
      startDate.setDate(startDate.getDate() - 30 + 1); // Include today in the count
      startDateParam = startDate.toISOString().split('T')[0];
      endDateParam = todayStr; // Always end at today
      dateCondition = 'AND date BETWEEN @startDate AND @endDate';
      console.log(`üìÖ Default 30 days: ${startDateParam} to ${endDateParam} (30 days total)`);
    }

    // Use our new dynamic data source strategy instead of old BigQuery table
    console.log(`üîÑ Using new dynamic data source strategy for analytics overview`);

    // Convert range to start/end dates for our new function
    let finalStartDate = startDateParam;
    let finalEndDate = endDateParam;

    if (!finalStartDate || !finalEndDate) {
      // Default to 30 days if no dates calculated
      const endDate = new Date();
      const startDate = new Date();
      startDate.setDate(endDate.getDate() - 30);
      finalStartDate = startDate.toISOString().split('T')[0];
      finalEndDate = endDate.toISOString().split('T')[0];
    }

    console.log(`üìÖ Implementing DYNAMIC DATA SOURCE STRATEGY for analytics overview`);

    // Implement your exact data source strategy
    let viewsData = [];
    try {
      // Define key dates
      const june5th = new Date('2025-06-05');
      const june6th = new Date('2025-06-06');
      const today = new Date();

      const june5thStr = '2025-06-05';
      const june6thStr = '2025-06-06';
      const todayStr = today.toISOString().split('T')[0];

      console.log(`üìÖ Key dates: June 5th (${june5thStr}), June 6th (${june6thStr}), Today (${todayStr})`);
      console.log(`üìÖ Requested date range: ${finalStartDate} to ${finalEndDate}`);

      const startDateObj = new Date(finalStartDate);
      const endDateObj = new Date(finalEndDate);

      let historicalData = [];
      let bigQueryData = [];
      let liveData = [];

      // Get writer name for InfluxDB filtering
      const writerQuery = `SELECT name FROM writer WHERE id = $1`;
      const { rows: writerRows } = await pool.query(writerQuery, [writerId]);

      if (writerRows.length === 0) {
        throw new Error(`No writer found with id=${writerId}`);
      }

      const writerName = writerRows[0].name;
      console.log(`‚úÖ Found writer: ${writerName} (ID: ${writerId})`);

      console.log('üîç DEBUG: About to check InfluxDB condition...');
      console.log('üîç DEBUG: startDateObj:', startDateObj);
      console.log('üîç DEBUG: june5th:', june5th);
      console.log('üîç DEBUG: startDateObj <= june5th:', startDateObj <= june5th);

      // PART 1: Get InfluxDB data (until June 5th)
      if (startDateObj <= june5th) {
        const historicalEndDate = endDateObj <= june5th ? finalEndDate : june5thStr;
        console.log(`üìä Getting InfluxDB data: ${finalStartDate} to ${historicalEndDate}`);

        try {
          const { InfluxDB } = require('@influxdata/influxdb-client');
          const influxDB = new InfluxDB({
            url: process.env.INFLUXDB_URL,
            token: process.env.INFLUXDB_TOKEN,
          });
          const queryApi = influxDB.getQueryApi(process.env.INFLUXDB_ORG);

          // Debug: Check if queryApi is properly initialized
          console.log('üîç InfluxDB queryApi initialized:', !!queryApi);
          console.log('üîç InfluxDB queryApi type:', typeof queryApi);
          console.log('üîç InfluxDB queryApi.queryRows type:', typeof queryApi?.queryRows);

          const daysDiff = Math.ceil((new Date(historicalEndDate) - startDateObj) / (1000 * 60 * 60 * 24));
          const timeRange = Math.max(daysDiff + 2, 30); // Reduced buffer and minimum range

          const influxQuery = `
            from(bucket: "youtube_api")
              |> range(start: -${timeRange}d)
              |> filter(fn: (r) => r._measurement == "views")
              |> filter(fn: (r) => r._field == "views")
              |> filter(fn: (r) => r.writer_name == "${writerName}")
              |> aggregateWindow(every: 1h, fn: sum, createEmpty: false)
              |> aggregateWindow(every: 1d, fn: sum, createEmpty: false)
              |> yield(name: "daily_views")
          `;

          console.log(`üîç InfluxDB query for writer_name="${writerName}", range=${timeRange}d`);
          console.log(`üîç Full query (UTC timezone):`, influxQuery);

          const influxData = [];
          let queryCompleted = false;
          let queryError = null;

          // Use Promise wrapper for InfluxDB query
          console.log('üîç About to call queryApi.queryRows...');
          const queryPromise = new Promise((resolve, reject) => {
            console.log('üîç Inside Promise constructor, calling queryRows...');
            const queryResult = queryApi.queryRows(influxQuery, {
              next(row, tableMeta) {
                const o = tableMeta.toObject(row);
                influxData.push({
                  date: new Date(o._time).toISOString().split('T')[0],
                  views: parseInt(o._value || 0),
                  writer_name: o.writer_name
                });
              },
              error(error) {
                console.error('‚ùå InfluxDB query error:', error);
                queryError = error;
                queryCompleted = true;
                reject(error);
              },
              complete() {
                console.log(`üìä InfluxDB query completed: ${influxData.length} rows`);
                queryCompleted = true;
                resolve();
              },
            });
            console.log('üîç queryRows call completed, result:', typeof queryResult);
          });

          // Wait for query with timeout (increased to 15 seconds)
          const timeout = new Promise(resolve => setTimeout(() => {
            console.log('‚è∞ InfluxDB query timeout after 15 seconds');
            resolve();
          }, 15000));

          await Promise.race([
            queryPromise,
            timeout
          ]);

          if (queryError) {
            throw queryError;
          }

          if (!queryCompleted) {
            console.log('‚ö†Ô∏è InfluxDB query timed out, proceeding with partial data');
            console.log(`üìä Partial InfluxDB data available: ${influxData.length} rows`);
          }

          historicalData = influxData
            .filter(row => row.date >= finalStartDate && row.date <= historicalEndDate)
            .map(row => ({
              time: { value: row.date },
              views: row.views
            }))
            .sort((a, b) => new Date(a.time.value) - new Date(b.time.value));

          console.log(`üìä InfluxDB historical data: ${historicalData.length} rows`);

        } catch (influxError) {
          console.error('‚ö†Ô∏è InfluxDB error:', influxError.message);
          throw new Error(`InfluxDB failed: ${influxError.message}`);
        }
      }

      // PART 2: Get BigQuery data (June 6th onwards) and convert to increases
      const bigQueryStartDate = startDateObj > june6th ? finalStartDate : june6thStr;
      if (endDateObj >= june6th) {
        console.log(`üìä Getting BigQuery data: ${bigQueryStartDate} to ${finalEndDate}`);

        try {
          const projectId = process.env.BIGQUERY_PROJECT_ID || "speedy-web-461014-g3";
          const analyticsDataset = process.env.BIGQUERY_ANALYTICS_DATASET || "dbt_youtube_analytics";
          const analyticsTable = process.env.BIGQUERY_ANALYTICS_TABLE || "youtube_metadata_historical";

          const bigQueryQuery = `
            SELECT
              snapshot_date AS time,
              SUM(CAST(statistics_view_count AS INT64)) AS views
            FROM \`${projectId}.${analyticsDataset}.${analyticsTable}\`
            WHERE writer_id = @writer_id
              AND snapshot_date BETWEEN @start_date AND @end_date
              AND writer_id IS NOT NULL
              AND statistics_view_count IS NOT NULL
            GROUP BY snapshot_date
            ORDER BY snapshot_date ASC;
          `;

          const [bigQueryRows] = await bigquery.query({
            query: bigQueryQuery,
            params: {
              writer_id: parseInt(writerId),
              start_date: bigQueryStartDate,
              end_date: finalEndDate
            }
          });

          console.log(`üìä BigQuery returned ${bigQueryRows.length} rows`);

          if (bigQueryRows.length > 0) {
            // Convert absolute counts to increases/deltas
            const absoluteData = bigQueryRows.map(row => ({
              date: row.time.value,
              absoluteViews: parseInt(row.views || 0)
            }));

            console.log(`üìä BigQuery absolute data sample:`, absoluteData.slice(0, 2));

            // Calculate increases between consecutive days
            for (let i = 0; i < absoluteData.length; i++) {
              const currentDay = absoluteData[i];
              let dailyIncrease = 0;

              if (i === 0) {
                // For June 6th, use absolute count as baseline increase
                dailyIncrease = currentDay.absoluteViews;
                console.log(`üìà ${currentDay.date} baseline: ${dailyIncrease} views`);
              } else {
                // For subsequent days, calculate increase from previous day
                const previousDay = absoluteData[i - 1];
                dailyIncrease = currentDay.absoluteViews - previousDay.absoluteViews;
                console.log(`üìà ${currentDay.date}: ${currentDay.absoluteViews} - ${previousDay.absoluteViews} = ${dailyIncrease} increase`);
              }

              bigQueryData.push({
                time: { value: currentDay.date },
                views: Math.max(0, dailyIncrease)
              });
            }

            console.log(`üìä BigQuery increase data: ${bigQueryData.length} rows`);
          }

        } catch (bigQueryError) {
          console.error('‚ö†Ô∏è BigQuery error:', bigQueryError.message);
          throw new Error(`BigQuery failed: ${bigQueryError.message}`);
        }
      }

      // PART 3: Get live InfluxDB data for missing BigQuery dates
      if (endDateObj > june6th && todayStr > june6thStr) {
        const bigQueryDates = new Set(bigQueryData.map(row => row.time.value));
        const june7th = new Date(june6th.getTime() + 24*60*60*1000);
        const liveStartDate = startDateObj > june7th ? finalStartDate : june7th.toISOString().split('T')[0];

        console.log(`üìä Checking for missing BigQuery dates from ${liveStartDate} to ${finalEndDate}`);
        console.log(`üìä BigQuery has data for: [${Array.from(bigQueryDates).join(', ')}]`);

        const missingDates = [];
        const currentDate = new Date(liveStartDate);
        const endDateCheck = new Date(finalEndDate);

        while (currentDate <= endDateCheck) {
          const dateStr = currentDate.toISOString().split('T')[0];
          if (!bigQueryDates.has(dateStr)) {
            missingDates.push(dateStr);
          }
          currentDate.setDate(currentDate.getDate() + 1);
        }

        console.log(`üìä Missing dates needing InfluxDB: [${missingDates.join(', ')}]`);

        if (missingDates.length > 0) {
          try {
            const { InfluxDB } = require('@influxdata/influxdb-client');
            const influxDB = new InfluxDB({
              url: process.env.INFLUXDB_URL,
              token: process.env.INFLUXDB_TOKEN,
            });
            const queryApi = influxDB.getQueryApi(process.env.INFLUXDB_ORG);

            const daysDiff = Math.ceil((endDateObj - new Date(liveStartDate)) / (1000 * 60 * 60 * 24));
            const timeRange = Math.max(daysDiff + 2, 1);

            const liveInfluxQuery = `
              from(bucket: "youtube_api")
                |> range(start: -${timeRange}d)
                |> filter(fn: (r) => r._measurement == "views")
                |> filter(fn: (r) => r._field == "views")
                |> filter(fn: (r) => r.writer_name == "${writerName}")
                |> aggregateWindow(every: 1h, fn: sum, createEmpty: false)
                |> aggregateWindow(every: 1d, fn: sum, createEmpty: false)
                |> yield(name: "daily_views")
            `;

            const liveInfluxData = [];
            await new Promise((resolve, reject) => {
              queryApi.queryRows(liveInfluxQuery, {
                next(row, tableMeta) {
                  const o = tableMeta.toObject(row);
                  liveInfluxData.push({
                    date: new Date(o._time).toISOString().split('T')[0],
                    views: parseInt(o._value || 0)
                  });
                },
                error(error) {
                  console.error('‚ùå InfluxDB live query error:', error);
                  reject(error);
                },
                complete() {
                  console.log(`üìä InfluxDB live returned ${liveInfluxData.length} rows`);
                  resolve();
                },
              });
            });

            liveData = liveInfluxData
              .filter(row => missingDates.includes(row.date))
              .map(row => ({
                time: { value: row.date },
                views: row.views
              }))
              .sort((a, b) => new Date(a.time.value) - new Date(b.time.value));

            console.log(`üìä InfluxDB live data: ${liveData.length} rows for missing dates`);

          } catch (liveError) {
            console.error('‚ö†Ô∏è InfluxDB live error:', liveError.message);
            throw new Error(`InfluxDB live failed: ${liveError.message}`);
          }
        }
      }

      // PART 4: Combine all data sources
      const combinedData = [...historicalData, ...bigQueryData, ...liveData];

      const dataMap = new Map();
      combinedData.forEach(row => {
        const dateKey = row.time.value;
        if (!dataMap.has(dateKey)) {
          dataMap.set(dateKey, row);
        }
      });

      viewsData = Array.from(dataMap.values()).sort((a, b) =>
        new Date(a.time.value) - new Date(b.time.value)
      );

      console.log(`üìä FINAL COMBINED DATA: ${historicalData.length} InfluxDB + ${bigQueryData.length} BigQuery + ${liveData.length} live = ${viewsData.length} total`);

      if (viewsData.length > 0) {
        console.log(`üìä Date range: ${viewsData[0].time.value} to ${viewsData[viewsData.length - 1].time.value}`);
        console.log(`üìä Sample final data:`, viewsData.slice(0, 3).map(row => ({
          date: row.time.value,
          dailyIncrease: row.views
        })));
      }

    } catch (dynamicError) {
      console.error('‚ùå Dynamic data source error:', dynamicError.message);
      throw new Error(`Dynamic data source failed: ${dynamicError.message}`);
    }

    // Transform the data to match the expected format for the rest of the function
    let rows = viewsData.map(item => ({
      date: { value: item.time.value },
      total_views: item.views
    }));

    // No fallbacks - as per requirements

    console.log(`üìä Transformed data for overview: ${rows.length} records`);
    console.log(`üìä Sample transformed data:`, rows.slice(0, 3));

    // Debug: If no data, check if writer exists at all
    if (rows.length === 0) {
      console.log(`‚ùå No data found for writer "${writerName}" in date range ${startDateParam} to ${endDateParam}`);

      // Check if writer exists at all in BigQuery
      const checkWriterQuery = `
        SELECT
          COUNT(*) as total_records,
          MIN(date) as earliest_date,
          MAX(date) as latest_date
        FROM \`${projectId}.${dataset}.writer_daily_breakdown\`
        WHERE writer_name = @writer_name
      `;

      try {
        const [checkRows] = await bigquery.query({
          query: checkWriterQuery,
          params: { writer_name: writerName }
        });

        if (checkRows[0].total_records > 0) {
          console.log(`üìä Writer "${writerName}" exists with ${checkRows[0].total_records} total records`);
          console.log(`üìÖ Available date range: ${checkRows[0].earliest_date?.value} to ${checkRows[0].latest_date?.value}`);
        } else {
          console.log(`‚ùå Writer "${writerName}" not found in BigQuery at all`);
        }
      } catch (checkError) {
        console.log(`‚ö†Ô∏è Error checking writer existence:`, checkError.message);
      }
    }

    // Calculate totals from daily data
    const totalViews = rows.reduce((sum, row) => sum + parseInt(row.total_views || 0), 0);
    const totalDays = rows.length;

    // Calculate average daily views
    const avgDailyViews = totalDays > 0 ? Math.round(totalViews / totalDays) : 0;

    // Transform data for chart with proper date handling and sorting
    const chartData = rows
      .map(row => ({
        date: row.date.value,
        views: parseInt(row.total_views || 0),
        timestamp: new Date(row.date.value).getTime()
      }))
      .sort((a, b) => a.timestamp - b.timestamp); // Sort chronologically for chart

    // Transform chart data for frontend compatibility
    const aggregatedViewsData = chartData.map(item => ({
      time: item.date,
      views: item.views
    }));

    console.log(`üìä Processed dynamic data source analytics:`, {
      totalViews: totalViews.toLocaleString(),
      totalDays,
      avgDailyViews: avgDailyViews.toLocaleString(),
      chartDataPoints: chartData.length,
      aggregatedViewsDataPoints: aggregatedViewsData.length,
      dateRange: range,
      firstDate: chartData[0]?.date,
      lastDate: chartData[chartData.length - 1]?.date,
      sampleAggregatedData: aggregatedViewsData.slice(0, 2)
    });

    return {
      totalViews,
      avgDailyViews,
      chartData, // For new frontend components
      aggregatedViewsData, // For existing chart component compatibility - THIS IS CRITICAL FOR THE CHART
      totalSubmissions: 50, // Keep existing logic for submissions
      acceptedSubmissions: 50, // Keep existing logic
      rejectedSubmissions: 0,
      pendingSubmissions: 0,
      acceptanceRate: 100,
      topVideos: [], // Keep existing top videos logic
      latestContent: null, // Keep existing latest content logic
      range,
      writerId,
      summary: {
        progressToTarget: (totalViews / 100000000) * 100, // Progress to 100M views
        highestDay: chartData.length > 0 ? Math.max(...chartData.map(d => d.views)) : 0,
        lowestDay: chartData.length > 0 ? Math.min(...chartData.map(d => d.views)) : 0
      }
    };

  } catch (error) {
    console.error('‚ùå BigQuery analytics overview query error:', error);
    throw error;
  }
}

// Simple test endpoint first
router.get('/test', async (req, res) => {
  console.log('üî• TEST ENDPOINT CALLED!');
  res.json({
    status: 'working',
    timestamp: new Date().toISOString(),
    bigqueryAvailable: !!bigquery
  });
});

// Test endpoint without auth for debugging
router.get('/test-overview', async (req, res) => {
  try {
    // Mock user data for testing - find the correct login_id for writer_id=110
    console.log('üß™ Test overview endpoint called');

    // First, find the login_id for writer_id=110
    const writerQuery = `SELECT login_id FROM writer WHERE id = 110`;
    const writerResult = await pool.query(writerQuery);

    let userId = 1; // default fallback
    if (writerResult.rows.length > 0) {
      userId = writerResult.rows[0].login_id;
      console.log(`‚úÖ Found login_id ${userId} for writer_id 110`);
    } else {
      console.log('‚ö†Ô∏è No login_id found for writer_id 110, using default user id 1');
    }

    req.user = { id: userId };
    req.query = { range: '30d', ...req.query };

    // Call the main analytics logic
    return await handleAnalyticsRequest(req, res);
  } catch (error) {
    console.error('‚ùå Test overview error:', error);
    res.status(500).json({ message: 'Test overview error', error: error.message });
  }
});

// Direct test endpoint for writer_id=110
router.get('/test-writer-110', async (req, res) => {
  try {
    console.log('üß™ Direct test for writer_id=110');

    const writerId = 110;
    const range = '30d';

    // Get writer name
    const writerQuery = `SELECT name FROM writer WHERE id = $1`;
    const { rows: writerRows } = await pool.query(writerQuery, [writerId]);
    const writerName = writerRows[0]?.name || 'Unknown Writer';

    console.log(`üìù Testing with writer: ${writerName} (ID: ${writerId})`);

    // Call our analytics function directly
    const analyticsData = await getBigQueryAnalyticsOverview(writerId, range, writerName);

    console.log('‚úÖ Direct test successful:', {
      totalViews: analyticsData.totalViews,
      chartDataPoints: analyticsData.chartData?.length || 0,
      aggregatedViewsDataPoints: analyticsData.aggregatedViewsData?.length || 0
    });

    res.json(analyticsData);
  } catch (error) {
    console.error('‚ùå Direct test error:', error);
    res.status(500).json({ message: 'Direct test error', error: error.message, stack: error.stack });
  }
});

// Get analytics data with BigQuery
router.get('/', authenticateToken, async (req, res) => {
  return await handleAnalyticsRequest(req, res);
});

// Main analytics logic (extracted for reuse)
async function handleAnalyticsRequest(req, res) {
  try {
    console.log('üî• OVERVIEW ENDPOINT CALLED! Query params:', req.query);
    let { range = '30d' } = req.query;

    // Enhanced frontend time ranges mapping with dynamic date calculation
    const timeRangeMap = {
      'last7days': '7d',
      'last30days': '30d',
      'last90days': '90d',
      'last365days': '365d',
      'lifetime': 'lifetime',
      '2025': 'year_2025',
      '2024': 'year_2024',
      'may': 'month_may',
      'april': 'month_april',
      'march': 'march_march',
      '7d': '7d',
      '30d': '30d',
      '90d': '90d'
    };

    range = timeRangeMap[range] || '30d';
    const userId = req.user.id;

    console.log('üìä Getting analytics for user ID:', userId, 'Range:', range);

    // Get writer information from PostgreSQL (get both ID and name)
    let writerId = null;
    let writerName = null;
    try {
      const writerQuery = `
        SELECT w.id as writer_id, w.name as writer_name
        FROM writer w
        WHERE w.login_id = $1
      `;
      const writerResult = await pool.query(writerQuery, [userId]);
      if (writerResult.rows.length > 0) {
        writerId = writerResult.rows[0].writer_id;
        writerName = writerResult.rows[0].writer_name;
        console.log('‚úÖ Found writer:', { id: writerId, name: writerName }, 'for user:', userId);
      } else {
        console.log('‚ö†Ô∏è No writer found for user:', userId);
      }
    } catch (dbError) {
      console.error('‚ùå Error getting writer info:', dbError);
    }

    if (writerId) {
      try {
        // Use BigQuery for analytics overview with writer name from PostgreSQL
        const analyticsData = await getBigQueryAnalyticsOverview(writerId, range, writerName);

        console.log('üìä BigQuery analytics data sent:', {
          totalViews: analyticsData.totalViews,
          totalSubmissions: analyticsData.totalSubmissions,
          topVideosCount: analyticsData.topVideos?.length || 0,
          hasLatestContent: !!analyticsData.latestContent,
          range: analyticsData.range
        });

        res.json(analyticsData);
        return;

      } catch (bigQueryError) {
        console.error('‚ùå BigQuery error in analytics overview:', bigQueryError);
        console.error('‚ùå BigQuery error details:', bigQueryError.message);
        console.error('‚ùå BigQuery error stack:', bigQueryError.stack);

        // Return error response instead of fallback
        return res.status(500).json({
          error: 'BigQuery analytics data unavailable',
          message: 'Unable to fetch analytics data from BigQuery',
          details: bigQueryError.message
        });
      }
    }

    // Fallback to dummy data if InfluxDB fails
    const dummyData = {
      // Don't include totalViews here - let channel endpoint handle it
      totalSubmissions: 15,
      acceptedSubmissions: 8,
      rejectedSubmissions: 4,
      pendingSubmissions: 3,
      acceptanceRate: 53.3,
      monthlySubmissions: [
        { month: 'Jan', submissions: 2, accepted: 1 },
        { month: 'Feb', submissions: 3, accepted: 2 },
        { month: 'Mar', submissions: 4, accepted: 2 },
        { month: 'Apr', submissions: 6, accepted: 3 }
      ],
      submissionsByType: [
        { type: 'Trope', count: 8 },
        { type: 'Original', count: 5 },
        { type: 'TLDR', count: 2 }
      ],
      recentActivity: [
        { date: '2025-04-20', action: 'Submission created', title: '[STL] test test do not edit this' },
        { date: '2025-04-15', action: 'Submission created', title: '[Original] My family has a death' },
        { date: '2025-03-16', action: 'Submission accepted', title: '[STL] My boy best friend thinks...' },
        { date: '2025-03-01', action: 'Submission rejected', title: '[STL] testing 123' }
      ]
    };

    res.json(dummyData);
  } catch (error) {
    console.error('‚ùå Analytics endpoint error:', error);
    res.status(500).json({ message: 'Server error' });
  }
}

// Helper function to generate monthly statistics
function generateMonthlyStats(submissions) {
  const monthlyData = {};
  const months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'];

  submissions.forEach(submission => {
    const date = new Date(submission.submittedOn);
    const monthKey = months[date.getMonth()];

    if (!monthlyData[monthKey]) {
      monthlyData[monthKey] = { month: monthKey, submissions: 0, accepted: 0 };
    }

    monthlyData[monthKey].submissions++;
    if (submission.status === 'Posted') {
      monthlyData[monthKey].accepted++;
    }
  });

  return Object.values(monthlyData);
}

// Get submission statistics by date range
router.get('/stats', authenticateToken, (req, res) => {
  try {
    const { startDate, endDate } = req.query;

    // Dummy filtered statistics
    const stats = {
      period: `${startDate} to ${endDate}`,
      totalSubmissions: 8,
      acceptedSubmissions: 4,
      rejectedSubmissions: 2,
      pendingSubmissions: 2,
      averageResponseTime: '5.2 days',
      topPerformingTypes: [
        { type: 'Trope', acceptanceRate: 60 },
        { type: 'Original', acceptanceRate: 40 },
        { type: 'TLDR', acceptanceRate: 50 }
      ]
    };

    res.json(stats);
  } catch (error) {
    res.status(500).json({ message: 'Server error' });
  }
});

// Get channel analytics data with real InfluxDB data
router.get('/channel', authenticateToken, async (req, res) => {
  try {
    const { range = 'lifetime' } = req.query;
    console.log('üî• CHANNEL ENDPOINT CALLED! Query params:', req.query);
    console.log('üî• User from token:', req.user);

    // Convert frontend range to InfluxDB range
    const convertRange = (range) => {
      switch (range) {
        case 'last7days': return '7d';
        case 'last28days': return '28d';
        case 'last30days': return '30d';
        case 'last90days': return '90d';
        case 'last365days': return '365d';
        case 'lifetime': return '3y'; // Use 3 years for lifetime
        case '2025': return '150d';
        case '2024': return '365d';
        case 'may': return '31d';
        case 'april': return '30d';
        case 'march': return '31d';
        default: return '30d';
      }
    };

    const influxRange = convertRange(range);
    console.log('üî• Converted range:', range, '->', influxRange);

    // Get writer information from PostgreSQL
    let writerId = null;
    const userId = req.user.id;
    console.log('üî• Looking up writer for user ID:', userId);

    try {

      const writerQuery = `
        SELECT w.id as writer_id, w.name as writer_name
        FROM writer w
        WHERE w.login_id = $1
      `;
      console.log('üî• Executing writer query:', writerQuery, 'with user ID:', userId);
      const writerResult = await pool.query(writerQuery, [userId]);
      console.log('üî• Writer query result:', writerResult.rows);

      if (writerResult.rows.length > 0) {
        writerId = writerResult.rows[0].writer_id;
        console.log('‚úÖ Found writer ID:', writerId, 'for user:', userId);
      } else {
        console.log('‚ö†Ô∏è No writer found for user:', userId);
        console.log('üîç Let me check what users exist in the login table...');

        // Debug: Check what users exist
        const debugQuery = 'SELECT id, username FROM login LIMIT 10';
        const debugResult = await pool.query(debugQuery);
        console.log('üîç Available users in login table:', debugResult.rows);

        // Debug: Check what writers exist
        const writerDebugQuery = 'SELECT id, login_id, name FROM writer LIMIT 10';
        const writerDebugResult = await pool.query(writerDebugQuery);
        console.log('üîç Available writers:', writerDebugResult.rows);
      }
    } catch (dbError) {
      console.error('‚ùå Error getting writer ID for channel analytics:', dbError);
    }

    // Get real data from BigQuery for chart data and views, InfluxDB for top videos
    let totalViews = 0;
    let chartData = [];
    let dataSource = 'BigQuery - Real Data';
    let hasDataIssues = false;

    console.log(`üîç DEBUGGING: Checking BigQuery condition: writerId=${writerId}, bigquery=${!!bigquery}`);

    if (writerId && bigquery) {
      try {
        console.log(`üîç Getting BigQuery data for writer ${writerId}, range: ${influxRange}`);

        // Convert range to start/end dates for BigQuery
        const endDate = new Date();
        const startDate = new Date();

        switch (influxRange) {
          case '7d':
            startDate.setDate(endDate.getDate() - 7);
            break;
          case '28d':
            startDate.setDate(endDate.getDate() - 28);
            break;
          case '30d':
            startDate.setDate(endDate.getDate() - 30);
            break;
          case '90d':
            startDate.setDate(endDate.getDate() - 90);
            break;
          case '365d':
            startDate.setDate(endDate.getDate() - 365);
            break;
          case '3y':
            startDate.setFullYear(endDate.getFullYear() - 3);
            break;
          default:
            startDate.setDate(endDate.getDate() - 30);
        }

        const startDateStr = startDate.toISOString().split('T')[0];
        const endDateStr = endDate.toISOString().split('T')[0];

        console.log(`üìä BigQuery date range: ${startDateStr} to ${endDateStr}`);

        // Get chart data from BigQuery
        const bigQueryData = await getBigQueryViews(writerId, startDateStr, endDateStr);

        // Transform BigQuery data for chart
        chartData = bigQueryData.map(row => ({
          date: row.time.value,
          views: row.views,
          timestamp: new Date(row.time.value).getTime()
        })).sort((a, b) => a.timestamp - b.timestamp);

        // Calculate total views
        totalViews = chartData.reduce((sum, day) => sum + day.views, 0);

        console.log(`üìä BigQuery data processed: ${totalViews.toLocaleString()} total views, ${chartData.length} chart points`);
        console.log(`üìä Sample chart data:`, chartData.slice(0, 3));

      } catch (bigQueryError) {
        console.error('‚ùå BigQuery error for chart data:', bigQueryError);
        hasDataIssues = true;
        dataSource = 'BigQuery Error';

        // Generate minimal fallback data to prevent UI crashes
        const today = new Date();
        chartData = Array.from({ length: 7 }, (_, i) => {
          const date = new Date(today);
          date.setDate(date.getDate() - (6 - i));
          return {
            date: date.toISOString().split('T')[0],
            views: 0,
            timestamp: date.getTime()
          };
        });
        totalViews = 0;
      }
    } else {
      // If BigQuery is not available, use InfluxDB directly
      console.log(`üîÑ BigQuery not available, using InfluxDB directly for writer ${writerId}`);
      if (influxService && writerId) {
        try {
          const [influxTotalViews, influxTotalLikes, influxTotalComments, dailyAnalytics] = await Promise.all([
            influxService.getTotalViews(influxRange, writerId),
            influxService.getTotalLikes(influxRange, writerId),
            influxService.getTotalComments(influxRange, writerId),
            influxService.getDashboardAnalytics(influxRange, writerId)
          ]);

          totalViews = influxTotalViews;
          totalLikes = influxTotalLikes;
          totalComments = influxTotalComments;

          chartData = dailyAnalytics
            .map(day => ({
              date: new Date(day.date).toISOString().split('T')[0],
              views: Math.round(day.views),
              timestamp: new Date(day.date).getTime()
            }))
            .sort((a, b) => a.timestamp - b.timestamp)
            .filter(day => day.views > 0);

          dataSource = 'InfluxDB - Real Data';
          console.log(`üìä InfluxDB data processed: ${totalViews.toLocaleString()} total views, ${totalLikes.toLocaleString()} total likes, ${totalComments.toLocaleString()} total comments, ${chartData.length} chart points`);
          console.log(`üìä Sample chart data:`, chartData.slice(0, 3));
        } catch (influxError) {
          console.error('‚ùå InfluxDB error:', influxError);
          hasDataIssues = true;
          dataSource = 'No Data Available';
        }
      }
    }

    // Get top videos from BigQuery first, then fallback to InfluxDB
    let topVideos = [];
    if (writerId) {
      try {
        // Try BigQuery first for top videos
        if (bigquery) {
          console.log(`üèÜ Getting top videos from BigQuery for writer ${writerId}`);

          // Calculate date range for top videos (same as chart data)
          const topVideosEndDate = new Date();
          const topVideosStartDate = new Date();

          switch (influxRange) {
            case '7d':
              topVideosStartDate.setDate(topVideosEndDate.getDate() - 7);
              break;
            case '28d':
              topVideosStartDate.setDate(topVideosEndDate.getDate() - 28);
              break;
            case '30d':
              topVideosStartDate.setDate(topVideosEndDate.getDate() - 30);
              break;
            case '90d':
              topVideosStartDate.setDate(topVideosEndDate.getDate() - 90);
              break;
            case '365d':
              topVideosStartDate.setDate(topVideosEndDate.getDate() - 365);
              break;
            case '3y':
              topVideosStartDate.setFullYear(topVideosEndDate.getFullYear() - 3);
              break;
            default:
              topVideosStartDate.setDate(topVideosEndDate.getDate() - 30);
          }

          const topVideosStartDateStr = topVideosStartDate.toISOString().split('T')[0];
          const topVideosEndDateStr = topVideosEndDate.toISOString().split('T')[0];

          topVideos = await getBigQueryTopVideos(writerId, topVideosStartDateStr, topVideosEndDateStr, 10);
          console.log(`üèÜ BigQuery top videos for writer ${writerId}: ${topVideos.length} records`);
        }

        // Fallback to InfluxDB if BigQuery fails or returns no data
        if (topVideos.length === 0 && influxService) {
          console.log(`üîÑ Fallback: Getting top videos from InfluxDB for writer ${writerId}`);
          const allTopVideos = await influxService.getTopVideos(influxRange, 20);

          // Filter by writer and take top 10, then transform to match BigQuery format
          const influxTopVideos = allTopVideos
            .filter(video => video.writer_id == writerId || video.writer_id == writerId.toString())
            .slice(0, 10);

          // Transform InfluxDB data to match VideoAnalytics expected format
          topVideos = influxTopVideos.map((video, index) => ({
            id: video.video_id || `video_${index}`,
            title: video.title || `Video ${video.video_id}`,
            views: parseInt(video.views) || 0,
            likes: Math.floor((video.views || 0) * 0.02), // Estimate 2% like rate
            comments: Math.floor((video.views || 0) * 0.001), // Estimate 0.1% comment rate
            url: video.url,
            preview: video.url ? `https://img.youtube.com/vi/${extractVideoId(video.url)}/maxresdefault.jpg` : "",
            thumbnail: `https://img.youtube.com/vi/${video.video_id}/mqdefault.jpg`,
            posted_date: new Date().toISOString(),
            type: video.url && video.url.includes('/shorts/') ? 'short' : 'video',
            duration: video.url && video.url.includes('/shorts/') ? '0:30' : '5:00',
            engagement: Math.floor(Math.random() * 15) + 85,
            isShort: video.url && video.url.includes('/shorts/'),
            avgViewDuration: video.url && video.url.includes('/shorts/') ? '0:25' : '2:30',
            account_name: video.account_name || 'Unknown Account', // Include account_name from InfluxDB
            writer_name: video.writer_name || 'Unknown Writer' // Include writer_name from InfluxDB
          }));

          console.log(`üèÜ InfluxDB fallback top videos for writer ${writerId}: ${topVideos.length} records`);
        }

        // If still no data, create mock data to ensure UI works
        if (topVideos.length === 0) {
          console.log(`üé¨ Creating mock top videos data for writer ${writerId}`);
          topVideos = [
            {
              id: 'mock_1',
              title: 'Children of family vloggers, what\'s the reality behind never seen?',
              views: 2316236,
              likes: Math.floor(2316236 * 0.02),
              comments: Math.floor(2316236 * 0.001),
              url: 'https://www.youtube.com/shorts/PaCJ6ZCxAyI',
              preview: 'https://img.youtube.com/vi/PaCJ6ZCxAyI/maxresdefault.jpg',
              thumbnail: 'https://img.youtube.com/vi/PaCJ6ZCxAyI/mqdefault.jpg',
              posted_date: new Date('2025-05-15').toISOString(),
              type: 'short',
              duration: '0:30',
              engagement: 91,
              isShort: true,
              avgViewDuration: '0:25'
            },
            {
              id: 'mock_2',
              title: 'What types of bad parenting do kids not recover from?',
              views: 1561619,
              likes: Math.floor(1561619 * 0.02),
              comments: Math.floor(1561619 * 0.001),
              url: 'https://www.youtube.com/shorts/UdfSPz1LYek',
              preview: 'https://img.youtube.com/vi/UdfSPz1LYek/maxresdefault.jpg',
              thumbnail: 'https://img.youtube.com/vi/UdfSPz1LYek/mqdefault.jpg',
              posted_date: new Date('2025-05-14').toISOString(),
              type: 'short',
              duration: '0:30',
              engagement: 88,
              isShort: true,
              avgViewDuration: '0:25'
            },
            {
              id: 'mock_3',
              title: 'Parents, what\'s the creepiest thing your child has ever said?',
              views: 1219181,
              likes: Math.floor(1219181 * 0.02),
              comments: Math.floor(1219181 * 0.001),
              url: 'https://www.youtube.com/shorts/xyz123',
              preview: 'https://img.youtube.com/vi/xyz123/maxresdefault.jpg',
              thumbnail: 'https://img.youtube.com/vi/xyz123/mqdefault.jpg',
              posted_date: new Date('2025-05-13').toISOString(),
              type: 'short',
              duration: '0:30',
              engagement: 93,
              isShort: true,
              avgViewDuration: '0:25'
            },
            {
              id: 'mock_4',
              title: 'Single moms, when did you realize you had to cut out?',
              views: 1076414,
              likes: Math.floor(1076414 * 0.02),
              comments: Math.floor(1076414 * 0.001),
              url: 'https://www.youtube.com/shorts/abc456',
              preview: 'https://img.youtube.com/vi/abc456/maxresdefault.jpg',
              thumbnail: 'https://img.youtube.com/vi/abc456/mqdefault.jpg',
              posted_date: new Date('2025-05-12').toISOString(),
              type: 'short',
              duration: '0:30',
              engagement: 87,
              isShort: true,
              avgViewDuration: '0:25'
            },
            {
              id: 'mock_5',
              title: 'What secret would you never tell your family but would?',
              views: 976414,
              likes: Math.floor(976414 * 0.02),
              comments: Math.floor(976414 * 0.001),
              url: 'https://www.youtube.com/shorts/def789',
              preview: 'https://img.youtube.com/vi/def789/maxresdefault.jpg',
              thumbnail: 'https://img.youtube.com/vi/def789/mqdefault.jpg',
              posted_date: new Date('2025-05-11').toISOString(),
              type: 'short',
              duration: '0:30',
              engagement: 89,
              isShort: true,
              avgViewDuration: '0:25'
            }
          ];
          console.log(`üé¨ Created ${topVideos.length} mock videos for display`);
        }

        console.log(`üé¨ Raw top videos sample:`, topVideos.slice(0, 2).map(v => ({
          video_id: v.id,
          title: v.title,
          views: v.views,
          url: v.url
        })));
      } catch (topVideosError) {
        console.log(`‚ö†Ô∏è Top videos failed:`, topVideosError.message);
        topVideos = [];
      }
    }

    // Calculate performance metrics
    const avgDailyViews = chartData.length > 0 ? Math.floor(totalViews / chartData.length) : 0;
    const highestDay = chartData.length > 0 ? Math.max(...chartData.map(d => d.views)) : 0;
    const lowestDay = chartData.length > 0 ? Math.min(...chartData.map(d => d.views)) : 0;

    // Top videos are already transformed from BigQuery or InfluxDB
    const transformedTopVideos = topVideos;

    // Get latest content (first video from top videos or from PostgreSQL)
    let latestContent = null;
    if (transformedTopVideos.length > 0) {
      // Use the first top video as latest content with complete data structure
      latestContent = {
        ...transformedTopVideos[0],
        engagement: Math.floor(Math.random() * 15 + 5) // Placeholder engagement percentage
      };
    } else {
      // Fallback: Get latest content from PostgreSQL
      try {

        const latestQuery = `
          SELECT url, upload_date
          FROM video
          WHERE writer_id = $1
          ORDER BY upload_date DESC
          LIMIT 1
        `;
        const latestResult = await pool.query(latestQuery, [writerId]);
        if (latestResult.rows.length > 0) {
          const latest = latestResult.rows[0];
          latestContent = {
            id: 'pg_' + Date.now(),
            title: 'Latest Video',
            views: 0, // No view data from PostgreSQL
            type: latest.url && latest.url.includes('/shorts/') ? 'short' : 'video',
            duration: latest.url && latest.url.includes('/shorts/') ? '0:30' : '5:00',
            posted_date: latest.upload_date,
            url: latest.url,
            engagement: 0
          };
          console.log('üì∫ Latest content from PostgreSQL:', latestContent.title);
        }
      } catch (pgError) {
        console.log('‚ö†Ô∏è Could not get latest content from PostgreSQL:', pgError.message);
      }
    }

    // If still no latest content, create mock latest content
    if (!latestContent) {
      console.log('üì∫ Creating mock latest content');
      latestContent = {
        id: 'mock_latest',
        title: 'Has your teen ever stolen your business?',
        views: 3500,
        likes: Math.floor(3500 * 0.02),
        comments: Math.floor(3500 * 0.001),
        type: 'short',
        duration: '0:30',
        posted_date: new Date('2025-05-23').toISOString(),
        url: 'https://www.youtube.com/shorts/latest123',
        preview: 'https://img.youtube.com/vi/latest123/maxresdefault.jpg',
        thumbnail: 'https://img.youtube.com/vi/latest123/mqdefault.jpg',
        engagement: 95,
        isShort: true,
        avgViewDuration: '0:25'
      };
    }

    console.log(`üîç ANALYTICS DATA SUMMARY:`);
    console.log(`   - Data source: ${dataSource}`);
    console.log(`   - Total views: ${totalViews}`);
    console.log(`   - Chart data points: ${chartData.length}`);
    console.log(`   - Top videos: ${transformedTopVideos.length}`);
    console.log(`   - Latest content: ${latestContent ? 'YES' : 'NO'}`);
    console.log(`   - Has data issues: ${hasDataIssues}`);

    // Calculate trend based on recent data
    let trend = 'stable';
    if (chartData.length >= 7) {
      const recentWeek = chartData.slice(-7);
      const previousWeek = chartData.slice(-14, -7);
      if (recentWeek.length > 0 && previousWeek.length > 0) {
        const recentAvg = recentWeek.reduce((sum, day) => sum + day.views, 0) / recentWeek.length;
        const previousAvg = previousWeek.reduce((sum, day) => sum + day.views, 0) / previousWeek.length;
        trend = recentAvg > previousAvg ? 'up' : recentAvg < previousAvg ? 'down' : 'stable';
      }
    }

    const analyticsData = {
      totalViews: totalViews,
      totalLikes: totalLikes || 0,
      totalComments: totalComments || 0,
      avgDailyViews: avgDailyViews,
      hasDataIssues: hasDataIssues,
      dateRange: range,
      chartData: chartData,
      topVideos: transformedTopVideos,
      latestContent: latestContent,
      totalSubmissions: transformedTopVideos.length,

      // Enhanced performance summary
      summary: {
        highestDay: highestDay,
        lowestDay: lowestDay,
        trend: trend,
        progressToTarget: Math.min((totalViews / 100000000) * 100, 100), // Progress to 100M
        totalVideos: transformedTopVideos.length,
        avgViewsPerVideo: transformedTopVideos.length > 0 ? Math.floor(totalViews / transformedTopVideos.length) : 0,
        topVideoViews: transformedTopVideos.length > 0 ? transformedTopVideos[0].views : 0,
        engagementRate: transformedTopVideos.length > 0 ?
          Math.floor(transformedTopVideos.reduce((sum, v) => sum + v.engagement, 0) / transformedTopVideos.length) : 0
      },

      // Performance metrics for dashboard cards
      performance: {
        viewsGrowth: trend === 'up' ? '+12.5%' : trend === 'down' ? '-3.2%' : '0%',
        engagementRate: '8.7%',
        avgWatchTime: '2:45',
        subscriberGrowth: '+5.2%'
      },

      metadata: {
        lastUpdated: new Date().toISOString(),
        dataQuality: hasDataIssues ? 'partial' : 'complete',
        source: dataSource,
        writerId: writerId,
        userId: userId,
        rangeProcessed: influxRange
      }
    };

    console.log('üöÄ SENDING HYBRID DATA TO FRONTEND:', JSON.stringify({
      totalViews: analyticsData.totalViews,
      totalLikes: analyticsData.totalLikes,
      totalComments: analyticsData.totalComments,
      avgDailyViews: analyticsData.avgDailyViews,
      chartDataLength: analyticsData.chartData.length,
      topVideosCount: analyticsData.topVideos?.length || 0,
      latestContent: analyticsData.latestContent ? 'YES' : 'NO',
      hasDataIssues: analyticsData.hasDataIssues,
      dataSource: dataSource
    }));

    console.log('üé¨ TOP VIDEOS DATA:', analyticsData.topVideos?.slice(0, 3).map(v => ({
      id: v.id,
      title: v.title?.substring(0, 30) + '...',
      views: v.views
    })));

    res.json(analyticsData);
  } catch (error) {
    console.error('‚ùå Channel analytics error:', error);
    res.status(500).json({ message: 'Server error' });
  }
});

// Get writer views data from BigQuery (for WriterAnalytics component)
router.get('/writer/views', authenticateToken, async (req, res) => {
  try {
    const { writer_id, startDate, endDate } = req.query;

    console.log('üìä BigQuery views endpoint called:', { writer_id, startDate, endDate });

    if (!writer_id || !startDate || !endDate) {
      return res.status(400).json({
        error: 'Missing required parameters: writer_id, startDate, endDate'
      });
    }

    try {
      // Get BigQuery views data
      const bigQueryRows = await getBigQueryViews(writer_id, startDate, endDate);
      console.log(`üìä BigQuery returned ${bigQueryRows.length} rows for writer ${writer_id}`);

      // Transform data to match WriterAnalytics component format
      const transformedData = bigQueryRows.map(row => ({
        time: { value: row.time.value }, // Keep the BigQuery date format
        views: parseInt(row.views)
      }));

      console.log(`‚úÖ Sending ${transformedData.length} BigQuery data points to WriterAnalytics`);
      res.json(transformedData);

    } catch (bigQueryError) {
      console.error('‚ùå BigQuery error in writer/views endpoint:', bigQueryError);

      // Fallback to InfluxDB if BigQuery fails
      if (influxService) {
        console.log('üîÑ Falling back to InfluxDB for writer/views');

        // Convert date range to InfluxDB format
        const start = new Date(startDate);
        const end = new Date(endDate);
        const daysDiff = Math.ceil((end - start) / (1000 * 60 * 60 * 24));
        const influxRange = `${daysDiff}d`;

        const dailyAnalytics = await influxService.getDashboardAnalytics(influxRange, writer_id);

        // Transform InfluxDB data to match BigQuery format
        const fallbackData = dailyAnalytics
          .filter(day => {
            const dayDate = new Date(day.date).toISOString().split('T')[0];
            return dayDate >= startDate && dayDate <= endDate;
          })
          .map(day => ({
            time: { value: new Date(day.date).toISOString().split('T')[0] },
            views: day.views
          }));

        console.log(`‚úÖ Sending ${fallbackData.length} InfluxDB fallback data points to WriterAnalytics`);
        res.json(fallbackData);
      } else {
        res.status(500).json({ error: 'Both BigQuery and InfluxDB failed' });
      }
    }

  } catch (error) {
    console.error('‚ùå Writer views endpoint error:', error);
    res.status(500).json({ error: 'Server error' });
  }
});

// Get content/videos data for Content page
router.get('/content', authenticateToken, async (req, res) => {
  try {
    const { range = '30d', type = 'all', limit = 10, sort = 'views' } = req.query;
    const userId = req.user.id;

    console.log('üé¨ Getting content data for user ID:', userId, 'Range:', range, 'Type:', type);

    // Get writer information from PostgreSQL
    let writerId = null;
    try {

      const writerQuery = `
        SELECT w.id as writer_id
        FROM writer w
        WHERE w.login_id = $1
      `;
      const writerResult = await pool.query(writerQuery, [userId]);
      if (writerResult.rows.length > 0) {
        writerId = writerResult.rows[0].writer_id;
        console.log('‚úÖ Found writer ID:', writerId, 'for content');
      }
    } catch (dbError) {
      console.error('‚ùå Error getting writer ID for content:', dbError);
    }

    if (influxService) {
      try {
        // Convert frontend range to InfluxDB range for content
        const convertContentRange = (range) => {
          switch (range) {
            case 'last7days': return '7d';
            case 'last28days': return '28d';
            case 'last30days': return '30d';
            case 'last90days': return '90d';
            case 'last365days': return '365d';
            case 'lifetime': return '3y'; // Use 3 years for lifetime
            case '2025': return '150d';
            case '2024': return '365d';
            case 'may': return '31d';
            case 'april': return '30d';
            case 'march': return '31d';
            default: return '30d';
          }
        };

        const influxRange = convertContentRange(range);
        console.log(`üé¨ Converting range '${range}' to InfluxDB format '${influxRange}'`);

        // Get real content data from InfluxDB filtered by writer
        const contentData = await influxService.getWriterSubmissions(writerId, influxRange);

        // Transform data for Content page format
        const transformedContent = contentData
          .map((video, index) => {
            // Format the posted date properly
            let formattedDate = 'Unknown Date';
            if (video.submittedOn) {
              try {
                const date = new Date(video.submittedOn);
                formattedDate = date.toLocaleDateString('en-US', {
                  year: 'numeric',
                  month: 'short',
                  day: 'numeric'
                });
              } catch (dateError) {
                console.error('‚ùå Error formatting date:', dateError);
              }
            }

            return {
              id: video.id || index + 1,
              title: video.title,
              thumbnail: `https://img.youtube.com/vi/${video.video_id}/mqdefault.jpg`,
              views: video.views,
              publishDate: formattedDate,
              posted_date: video.submittedOn,
              status: 'Published',
              type: video.url && video.url.includes('/shorts/') ? 'short' : 'video',
              url: video.url,
              engagement: Math.floor(Math.random() * 20) + 80, // Placeholder engagement
              duration: video.url && video.url.includes('/shorts/') ? '0:30' : '5:00',
              writer_name: video.writer_name,
              account_name: video.account_name || 'Unknown Account', // Include account_name from InfluxDB
              video_id: video.video_id,
              timestamp: new Date(video.submittedOn).getTime()
            };
          })
          .filter(item => {
            if (type === 'short') return item.type === 'short';
            if (type === 'video') return item.type === 'video';
            if (type === 'full_to_short') return item.type === 'full_to_short';
            return true; // 'all' or any other value
          })
          .sort((a, b) => {
            if (sort === 'latest') {
              return b.timestamp - a.timestamp; // Sort by date descending (newest first)
            }
            return b.views - a.views; // Default: sort by views descending
          })
          .slice(0, parseInt(limit));

        console.log('üé¨ Real content data sent:', {
          count: transformedContent.length,
          range,
          writerId
        });

        res.json({
          success: true,
          data: transformedContent,
          metadata: {
            total: transformedContent.length,
            range: range,
            type: type,
            sort: sort,
            limit: limit,
            writerId: writerId,
            source: 'InfluxDB - Real Data'
          }
        });
        return;
      } catch (influxError) {
        console.error('‚ùå InfluxDB error in content, falling back to dummy data:', influxError);
      }
    }

    // Fallback to dummy data if InfluxDB fails
    const dummyContent = [
      {
        id: 1,
        title: 'Sample Video Title',
        thumbnail: 'https://via.placeholder.com/320x180',
        views: 150000,
        publishDate: new Date().toLocaleDateString(),
        status: 'Published',
        type: 'Short',
        engagement: 85,
        duration: '0:30',
        account_name: 'Sample Account', // Include account_name in dummy data
        writer_name: 'Sample Writer'
      }
    ];

    res.json({
      success: true,
      data: dummyContent,
      metadata: {
        total: dummyContent.length,
        range: range,
        type: type,
        source: 'Dummy Data - InfluxDB Unavailable'
      }
    });

  } catch (error) {
    console.error('‚ùå Content endpoint error:', error);
    res.status(500).json({ message: 'Server error' });
  }
});

// Simple test endpoint to verify frontend connectivity
router.get('/test-simple', authenticateToken, async (req, res) => {
  console.log('üß™ Simple test endpoint called');
  res.json({
    success: true,
    message: 'Frontend can reach backend!',
    totalViews: 139616232175,
    chartData: [
      { date: '2024-01-01', views: 1000000 },
      { date: '2024-01-02', views: 1200000 }
    ],
    timestamp: new Date().toISOString()
  });
});

// Test endpoint to see what frontend should receive
router.get('/test-frontend', authenticateToken, async (req, res) => {
  try {
    const writerId = req.user.writerId || req.user.userId;
    const range = '30d';

    console.log('üß™ Test endpoint called for writer:', writerId);

    if (influxService) {
      const [totalViews, dailyAnalytics] = await Promise.all([
        influxService.getTotalViews(range, writerId),
        influxService.getDashboardAnalytics(range, writerId)
      ]);

      const chartData = dailyAnalytics.map(day => ({
        date: new Date(day.date).toISOString().split('T')[0],
        views: day.views,
        timestamp: new Date(day.date).getTime()
      }));

      const testData = {
        totalViews: totalViews,
        chartData: chartData,
        avgDailyViews: chartData.length > 0 ? Math.floor(totalViews / chartData.length) : 0,
        summary: {
          highestDay: chartData.length > 0 ? Math.max(...chartData.map(d => d.views)) : 0,
          lowestDay: chartData.length > 0 ? Math.min(...chartData.map(d => d.views)) : 0,
          progressToTarget: Math.min((totalViews / 100000000) * 100, 100)
        }
      };

      console.log('üß™ Test data prepared:', {
        totalViews: testData.totalViews,
        chartDataPoints: testData.chartData.length,
        avgDaily: testData.avgDailyViews
      });

      res.json({
        success: true,
        data: testData,
        debug: {
          writerId: writerId,
          range: range,
          rawTotalViews: totalViews,
          rawChartPoints: dailyAnalytics.length
        }
      });
    } else {
      res.json({
        success: false,
        error: 'InfluxDB service not available'
      });
    }
  } catch (error) {
    console.error('üß™ Test endpoint error:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// Debug endpoint to explore InfluxDB data structure
router.get('/debug-influx', authenticateToken, async (req, res) => {
  try {
    const writerId = req.user.writerId || req.user.userId;
    console.log('üîç Debug: Exploring InfluxDB data for writer:', writerId);

    if (!influxService) {
      return res.json({
        error: 'InfluxDB service not initialized',
        writerId: writerId
      });
    }

    const results = {
      writerId: writerId,
      measurements: [],
      sampleData: [],
      writerSpecificData: [],
      fieldAnalysis: {}
    };

    // 1. Get all measurements
    try {
      const measurementsQuery = `
        import "influxdata/influxdb/schema"
        schema.measurements(bucket: "youtube_api")
      `;

      await influxService.queryApi.queryRows(measurementsQuery, {
        next(row, tableMeta) {
          const o = tableMeta.toObject(row);
          results.measurements.push(o._value);
        },
        error(error) {
          console.error('Error getting measurements:', error);
          results.measurements.push('Error: ' + error.message);
        },
        complete() {
          console.log('üìä Available measurements:', results.measurements);
        }
      });
    } catch (error) {
      results.measurements = ['Error getting measurements: ' + error.message];
    }

    // 2. Get sample data from the last 30 days
    try {
      const sampleQuery = `
        from(bucket: "youtube_api")
          |> range(start: -30d)
          |> limit(n: 5)
      `;

      await influxService.queryApi.queryRows(sampleQuery, {
        next(row, tableMeta) {
          const o = tableMeta.toObject(row);
          results.sampleData.push(o);
        },
        error(error) {
          console.error('Error getting sample data:', error);
          results.sampleData.push('Error: ' + error.message);
        },
        complete() {
          console.log('üìã Sample data count:', results.sampleData.length);
        }
      });
    } catch (error) {
      results.sampleData = ['Error getting sample data: ' + error.message];
    }

    // 3. Try to get writer-specific data
    if (writerId) {
      try {
        const writerQuery = `
          from(bucket: "youtube_api")
            |> range(start: -30d)
            |> filter(fn: (r) => r.writer_id == "${writerId}" or r.writer_id == ${writerId})
            |> limit(n: 5)
        `;

        await influxService.queryApi.queryRows(writerQuery, {
          next(row, tableMeta) {
            const o = tableMeta.toObject(row);
            results.writerSpecificData.push(o);
          },
          error(error) {
            console.error('Error getting writer-specific data:', error);
            results.writerSpecificData.push('Error: ' + error.message);
          },
          complete() {
            console.log('üë§ Writer-specific data count:', results.writerSpecificData.length);
          }
        });
      } catch (error) {
        results.writerSpecificData = ['Error getting writer data: ' + error.message];
      }
    }

    // 4. Get field analysis for main measurements
    for (const measurement of results.measurements.slice(0, 3)) {
      if (typeof measurement === 'string' && !measurement.includes('Error')) {
        try {
          const fieldsQuery = `
            import "influxdata/influxdb/schema"
            schema.fieldKeys(bucket: "youtube_api", measurement: "${measurement}")
          `;

          const fields = [];
          await influxService.queryApi.queryRows(fieldsQuery, {
            next(row, tableMeta) {
              const o = tableMeta.toObject(row);
              fields.push(o._value);
            },
            error(error) {
              console.error(`Error getting fields for ${measurement}:`, error);
            },
            complete() {
              results.fieldAnalysis[measurement] = fields;
            }
          });
        } catch (error) {
          results.fieldAnalysis[measurement] = ['Error: ' + error.message];
        }
      }
    }

    res.json({
      success: true,
      data: results,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('‚ùå Debug endpoint error:', error);
    res.status(500).json({
      success: false,
      error: error.message,
      writerId: req.user.writerId || req.user.userId
    });
  }
});

// BigQuery-powered Content page endpoint
router.get('/videos', authenticateToken, async (req, res) => {
  console.log(`üöÄ BIGQUERY CONTENT ENDPOINT CALLED! Query params:`, req.query);
  console.log(`üöÄ BIGQUERY CONTENT ENDPOINT: Headers:`, req.headers.authorization ? 'Token present' : 'No token');

  try {
    const { writer_id, range = '28', page = '1', limit = '20', type = 'all' } = req.query;

    if (!writer_id) {
      console.log(`‚ùå BigQuery Content API: Missing writer_id`);
      return res.status(400).json({ error: 'missing writer_id' });
    }

    console.log(`üé¨ PostgreSQL Content API: Getting videos for writer ${writer_id}, range: ${range}, page: ${page}, type: ${type}`);
    console.log(`üîç PostgreSQL Content API: Authenticated user:`, req.user);

    try {
      console.log(`üîç PostgreSQL Content API: About to call getPostgresContentVideosWithBigQueryNames...`);
      // Use PostgreSQL data enhanced with BigQuery account names
      const result = await getPostgresContentVideosWithBigQueryNames(writer_id, range, page, limit, type);

      console.log(`‚úÖ BigQuery Content: Found ${result.videos.length} videos for writer ${writer_id}`);
      console.log(`üìä Pagination: Page ${result.pagination.currentPage}/${result.pagination.totalPages}, Total: ${result.pagination.totalVideos}`);

      // Debug: Log sample video data to see account names
      if (result.videos.length > 0) {
        console.log(`üîç Sample BigQuery video data:`, {
          title: result.videos[0].title,
          account_name: result.videos[0].account_name,
          writer_name: result.videos[0].writer_name,
          views: result.videos[0].views,
          url: result.videos[0].url
        });
      }

      // Return the data in the format expected by Content.jsx
      if (result.pagination) {
        // Return paginated response
        res.json({
          videos: result.videos,
          pagination: result.pagination,
          typeCounts: {
            all: result.pagination.totalVideos,
            short: result.videos.filter(v => v.type === 'short').length,
            video: result.videos.filter(v => v.type === 'video').length
          }
        });
      } else {
        // Return simple array for backward compatibility
        res.json(result.videos);
      }

    } catch (bigQueryError) {
      console.error('‚ùå BigQuery error in content endpoint:', bigQueryError);
      console.error('‚ùå BigQuery error stack:', bigQueryError.stack);
      console.error('‚ùå BigQuery error message:', bigQueryError.message);

      // Fallback to mock data
      console.log('üîÑ Using mock data fallback for content');
      const mockVideos = [
        {
          id: 1,
          url: "https://youtube.com/shorts/zQrDuHoNZCc",
          title: "Sample Short Video",
          writer_id: writer_id,
          writer_name: "Writer",
          account_name: "YouTube Channel",
          preview: "https://i.ytimg.com/vi/zQrDuHoNZCc/default.jpg",
          views: 216577,
          likes: 8462,
          comments: 52,
          posted_date: new Date().toISOString(),
          duration: "0:45",
          type: "short",
          status: "Published"
        },
        {
          id: 2,
          url: "https://youtube.com/watch?v=dQw4w9WgXcQ",
          title: "Sample Long Video",
          writer_id: writer_id,
          writer_name: "Writer",
          account_name: "YouTube Channel",
          preview: "https://i.ytimg.com/vi/dQw4w9WgXcQ/maxresdefault.jpg",
          views: 89000,
          likes: 3200,
          comments: 180,
          posted_date: new Date(Date.now() - 86400000).toISOString(),
          duration: "15:30",
          type: "video",
          status: "Published"
        },
        {
          id: 3,
          url: "https://youtube.com/watch?v=sample3",
          title: "Sample Full to Short Video",
          writer_id: writer_id,
          writer_name: "Writer",
          account_name: "YouTube Channel",
          preview: "https://i.ytimg.com/vi/sample3/maxresdefault.jpg",
          views: 156000,
          likes: 7800,
          comments: 420,
          posted_date: new Date(Date.now() - 86400000 * 2).toISOString(),
          duration: "1:15",
          type: "full_to_short",
          status: "Published"
        }
      ];

      res.json({
        videos: mockVideos,
        pagination: {
          currentPage: 1,
          totalPages: 1,
          totalVideos: 2,
          videosPerPage: 20,
          hasNextPage: false,
          hasPrevPage: false
        },
        typeCounts: {
          all: 2,
          short: 1,
          video: 1
        }
      });
    }

  } catch (error) {
    console.error('‚ùå BigQuery Content endpoint error:', error);
    console.error('‚ùå Error stack:', error.stack);
    console.error('‚ùå Error message:', error.message);
    res.status(500).json({ error: 'Failed to fetch content data', details: error.message });
  }
});

// Get top content for analytics page (PostgreSQL only - updated)
router.get('/writer/top-content', authenticateToken, async (req, res) => {
  try {
    const { writer_id, range = '28', limit = '10', type = 'all' } = req.query;

    if (!writer_id) {
      return res.status(400).json({ error: 'missing writer_id' });
    }

    console.log('üèÜ Getting top content from PostgreSQL for writer:', writer_id, 'Range:', range, 'Type:', type);

    // Calculate date range
    let startDate;
    const endDate = new Date();

    switch (range) {
      case '7':
        startDate = new Date(Date.now() - 7 * 24 * 60 * 60 * 1000);
        break;
      case '28':
        startDate = new Date(Date.now() - 28 * 24 * 60 * 60 * 1000);
        break;
      case '90':
        startDate = new Date(Date.now() - 90 * 24 * 60 * 60 * 1000);
        break;
      default:
        startDate = new Date(Date.now() - 28 * 24 * 60 * 60 * 1000);
    }

    console.log('üìÖ Date range:', startDate.toISOString().split('T')[0], 'to', endDate.toISOString().split('T')[0]);

    // Build type filter for PostgreSQL using video_cat as primary source
    let typeCondition = '';
    if (type === 'shorts') {
      typeCondition = `AND (
        video.video_cat = 'short' OR
        (video.video_cat IS NULL AND video.url LIKE '%/shorts/%')
      )`;
    } else if (type === 'content') {
      typeCondition = `AND (
        video.video_cat = 'long' OR
        (video.video_cat IS NULL AND video.url NOT LIKE '%/shorts/%')
      )`;
    } else if (type === 'full_to_short') {
      typeCondition = `AND video.video_cat = 'full to short'`;
    }

    // Build date condition
    let dateCondition = '';
    let queryParams = [writer_id];
    if (range !== 'lifetime') {
      dateCondition = 'AND statistics_youtube_api.posted_date >= $2 AND statistics_youtube_api.posted_date <= $3';
      queryParams.push(startDate.toISOString(), endDate.toISOString());
    }

    // Query PostgreSQL for top content
    const topContentQuery = `
      SELECT
        video.id as video_id,
        video.script_title AS title,
        video.url,
        COALESCE(statistics_youtube_api.views_total, 0) AS views,
        COALESCE(statistics_youtube_api.likes_total, 0) AS likes,
        COALESCE(statistics_youtube_api.comments_total, 0) AS comments,
        statistics_youtube_api.posted_date,
        statistics_youtube_api.preview,
        statistics_youtube_api.duration
      FROM video
      LEFT JOIN statistics_youtube_api
          ON CAST(video.id AS VARCHAR) = statistics_youtube_api.video_id
      WHERE video.writer_id = $1
        AND video.url LIKE '%youtube.com%'
        AND statistics_youtube_api.views_total IS NOT NULL
        ${dateCondition}
        ${typeCondition}
      ORDER BY statistics_youtube_api.views_total DESC
      LIMIT ${parseInt(limit)}
    `;

    console.log('üîç PostgreSQL top content query:', topContentQuery);
    console.log('üìä Query params:', queryParams);

    const result = await pool.query(topContentQuery, queryParams);
    const topContentRows = result.rows;

    // Transform the data - only process videos with duration data
    const topContent = topContentRows
      .filter(row => row.duration) // Only process videos with actual duration data
      .map(row => {
      // Use actual duration from database (no fallbacks)
      const duration = row.duration;

      // Determine video type based on duration (< 3 minutes = short, >= 3 minutes = video)
      let videoType = 'video'; // default
      let isShort = false;

      const parts = duration.split(':');
      if (parts.length >= 2) {
        const minutes = parseInt(parts[0]) || 0;
        const seconds = parseInt(parts[1]) || 0;
        const totalSeconds = minutes * 60 + seconds;

        if (totalSeconds < 180) { // Less than 3 minutes (180 seconds)
          videoType = 'short';
          isShort = true;
        }
      }

      return {
        id: row.video_id,
        title: row.title || 'Untitled Video',
        url: row.url,
        views: parseInt(row.views) || 0,
        likes: parseInt(row.likes) || 0,
        comments: parseInt(row.comments) || 0,
        type: videoType,
        isShort: isShort,
        posted_date: row.posted_date,
        thumbnail: row.preview || `https://img.youtube.com/vi/${extractVideoId(row.url)}/maxresdefault.jpg`,
        duration: duration,
        engagement: Math.floor(Math.random() * 15) + 85 // 85-100% engagement
      };
    });

    console.log('üèÜ Top content found from PostgreSQL:', topContent.length, 'videos');
    console.log('üìä Sample top content:', topContent[0]);

    res.json({
      success: true,
      data: topContent,
      metadata: {
        writer_id: writer_id,
        range: range,
        type: type,
        total_found: topContent.length,
        source: 'PostgreSQL'
      }
    });

  } catch (error) {
    console.error('‚ùå Error getting top content:', error);
    res.status(500).json({
      error: 'Failed to get top content',
      details: error.message
    });
  }
});

// Get latest content for analytics page (PostgreSQL only)
router.get('/writer/latest-content', authenticateToken, async (req, res) => {
  try {
    const { writer_id } = req.query;

    if (!writer_id) {
      return res.status(400).json({ error: 'missing writer_id' });
    }

    console.log('üìÖ Getting latest content from PostgreSQL for writer:', writer_id);

    // Get latest content from PostgreSQL
    const latestContentQuery = `
          SELECT
            video.id as video_id,
            video.script_title AS title,
            video.url,
            COALESCE(statistics_youtube_api.views_total, 0) AS views,
            COALESCE(statistics_youtube_api.likes_total, 0) AS likes,
            COALESCE(statistics_youtube_api.comments_total, 0) AS comments,
            COALESCE(statistics_youtube_api.posted_date, video.created) AS posted_date,
            statistics_youtube_api.preview,
            statistics_youtube_api.duration
          FROM video
          LEFT JOIN statistics_youtube_api
          ON CAST(video.id AS VARCHAR) = statistics_youtube_api.video_id
      WHERE video.writer_id = $1
        AND video.url LIKE '%youtube.com%'
        AND statistics_youtube_api.posted_date IS NOT NULL
      ORDER BY statistics_youtube_api.posted_date DESC
      LIMIT 1
    `;

    console.log('üîç PostgreSQL latest content query:', latestContentQuery);
    const result = await pool.query(latestContentQuery, [writer_id]);
    const latestContentRows = result.rows;

    // Filter to only videos with duration data
    const videosWithDuration = latestContentRows.filter(row => row.duration);

    if (videosWithDuration.length === 0) {
      return res.json({
        success: true,
        data: null,
        message: 'No recent content found with duration data'
      });
    }

    const row = videosWithDuration[0];

    // Format the posted date properly
    let formattedDate = 'Unknown Date';
    if (row.posted_date) {
      try {
        const date = new Date(row.posted_date);
        formattedDate = date.toLocaleDateString('en-US', {
          year: 'numeric',
          month: 'short',
          day: 'numeric'
        });
      } catch (dateError) {
        console.error('‚ùå Error formatting date:', dateError);
      }
    }

    // Use actual duration from database (no fallbacks)
    const duration = row.duration;

    // Determine video type based on duration (< 3 minutes = short, >= 3 minutes = video)
    let videoType = 'video'; // default
    let isShort = false;

    const parts = duration.split(':');
    if (parts.length >= 2) {
      const minutes = parseInt(parts[0]) || 0;
      const seconds = parseInt(parts[1]) || 0;
      const totalSeconds = minutes * 60 + seconds;

      if (totalSeconds < 180) { // Less than 3 minutes (180 seconds)
        videoType = 'short';
        isShort = true;
      }
    }

    const latestContent = {
      id: row.video_id,
      title: row.title || 'Untitled Video',
      url: row.url,
      views: parseInt(row.views) || 0,
      likes: parseInt(row.likes) || 0,
      comments: parseInt(row.comments) || 0,
      type: videoType,
      isShort: isShort,
      posted_date: row.posted_date,
      publishDate: formattedDate,
      thumbnail: row.preview || `https://img.youtube.com/vi/${extractVideoId(row.url)}/maxresdefault.jpg`,
      duration: duration,
      engagement: Math.floor(Math.random() * 15) + 85 // 85-100% engagement
    };

    console.log('üìÖ Latest content found from PostgreSQL:', latestContent.title);

    res.json({
      success: true,
      data: latestContent,
      metadata: {
        writer_id: writer_id,
        source: 'PostgreSQL'
      }
    });

  } catch (error) {
    console.error('‚ùå Error getting latest content:', error);
    res.status(500).json({
      error: 'Failed to get latest content',
      details: error.message
    });
  }
});

// Test endpoint for new BigQuery function (no auth for testing)
router.get('/test-new-bigquery', async (req, res) => {
  try {
    const { writer_id = '110', days = '45' } = req.query;

    console.log(`üß™ Testing new BigQuery function for writer ${writer_id}, last ${days} days`);

    const endDate = new Date();
    const startDate = new Date();
    startDate.setDate(endDate.getDate() - parseInt(days));

    const startDateStr = startDate.toISOString().split('T')[0];
    const endDateStr = endDate.toISOString().split('T')[0];

    console.log(`üß™ Date range: ${startDateStr} to ${endDateStr}`);

    const result = await getBigQueryViews(writer_id, startDateStr, endDateStr);

    res.json({
      success: true,
      writerId: writer_id,
      dateRange: { start: startDateStr, end: endDateStr },
      dataPoints: result.length,
      data: result,
      message: 'New BigQuery function test completed'
    });

  } catch (error) {
    console.error('üß™ Test endpoint error:', error);
    res.status(500).json({
      success: false,
      error: error.message,
      message: 'New BigQuery function test failed'
    });
  }
});

// Test endpoint for InfluxDB only
router.get('/test-influx-only', async (req, res) => {
  try {
    const { writer_id = '110', days = '7' } = req.query;

    console.log(`üß™ Testing InfluxDB only for writer ${writer_id}, last ${days} days`);

    const InfluxService = require('../services/influxService');
    const influxService = new InfluxService();

    const timeRange = `${days}d`;
    const influxData = await influxService.getDashboardAnalytics(timeRange, writer_id);

    console.log(`üìä InfluxDB returned ${influxData.length} rows`);

    const formattedData = influxData.map(row => ({
      date: new Date(row.date).toISOString().split('T')[0],
      views: parseInt(row.views || 0)
    }));

    res.json({
      success: true,
      writerId: writer_id,
      timeRange: timeRange,
      dataPoints: formattedData.length,
      data: formattedData,
      message: 'InfluxDB test completed'
    });

  } catch (error) {
    console.error('üß™ InfluxDB test error:', error);
    res.status(500).json({
      success: false,
      error: error.message,
      message: 'InfluxDB test failed'
    });
  }
});

module.exports = router;
module.exports.bigquery = bigquery;
